
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
        <link rel="next" href="../opensearch_productionize/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>OpenSearch Introduction - OpenSearch for Vector and Hybrid Search</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../styles/overrides.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#opensearch-theory-to-implementation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="OpenSearch for Vector and Hybrid Search" class="md-header__button md-logo" aria-label="OpenSearch for Vector and Hybrid Search" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            OpenSearch for Vector and Hybrid Search
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              OpenSearch Introduction
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="OpenSearch for Vector and Hybrid Search" class="md-nav__button md-logo" aria-label="OpenSearch for Vector and Hybrid Search" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    OpenSearch for Vector and Hybrid Search
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    OpenSearch Introduction
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    OpenSearch Introduction
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-i-search-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Part I: Search Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part I: Search Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#traditional-text-based-search" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional Text-Based Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Traditional Text-Based Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-evolution-of-keyword-search" class="md-nav__link">
    <span class="md-ellipsis">
      The Evolution of Keyword Search
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bm25-the-modern-standard" class="md-nav__link">
    <span class="md-ellipsis">
      BM25: The Modern Standard
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#where-text-search-excels" class="md-nav__link">
    <span class="md-ellipsis">
      Where Text Search Excels
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limitations-of-text-based-search" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations of Text-Based Search
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-search-evolution" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Search Evolution
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vector Search Evolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-semantic-understanding-breakthrough" class="md-nav__link">
    <span class="md-ellipsis">
      The Semantic Understanding Breakthrough
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-search-addresses-text-search-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Search Addresses Text Search Limitations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-mathematics-of-semantic-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      The Mathematics of Semantic Similarity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#search-approach-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Search Approach Comparison
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Search Approach Comparison">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#detailed-comparison-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Detailed Comparison Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehensive-decision-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Decision Framework
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-progression-text-vector-hybrid_1" class="md-nav__link">
    <span class="md-ellipsis">
      The Progression: Text → Vector → Hybrid
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Progression: Text → Vector → Hybrid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hybrid-search-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Search Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#real-world-hybrid-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Real-World Hybrid Examples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Strategy
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reranking-refining-search-results" class="md-nav__link">
    <span class="md-ellipsis">
      Reranking: Refining Search Results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reranking: Refining Search Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-two-stage-search-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      The Two-Stage Search Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-reranking-is-essential" class="md-nav__link">
    <span class="md-ellipsis">
      Why Reranking is Essential
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-reranking-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Reranking Approaches
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Approaches
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-ii-vector-search-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Part II: Vector Search Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part II: Vector Search Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#high-dimensional-geometry-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      High-Dimensional Geometry Challenges
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#similarity-metrics-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Similarity Metrics Deep Dive
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#approximate-nearest-neighbor-ann-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Approximate Nearest Neighbor (ANN) Algorithms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hnsw-hierarchical-navigable-small-world" class="md-nav__link">
    <span class="md-ellipsis">
      HNSW: Hierarchical Navigable Small World
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HNSW: Hierarchical Navigable Small World">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conceptual-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Conceptual Understanding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-parameter-analysis-and-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Parameter Analysis and Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#real-world-performance-characteristics" class="md-nav__link">
    <span class="md-ellipsis">
      Real-World Performance Characteristics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ivf-inverted-file-index" class="md-nav__link">
    <span class="md-ellipsis">
      IVF: Inverted File Index
    </span>
  </a>
  
    <nav class="md-nav" aria-label="IVF: Inverted File Index">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conceptual-foundation-and-mathematical-intuition" class="md-nav__link">
    <span class="md-ellipsis">
      Conceptual Foundation and Mathematical Intuition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-ivf-techniques-and-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced IVF Techniques and Optimizations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#product-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Product Quantization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Product Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conceptual-understanding-and-mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Conceptual Understanding and Mathematical Foundation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-selection-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm Selection Guide
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Algorithm Selection Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#comprehensive-decision-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Decision Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-specific-optimization-guidelines" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm-Specific Optimization Guidelines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hybrid-algorithm-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Algorithm Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iii-opensearch-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Part III: OpenSearch Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part III: OpenSearch Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#opensearch-vector-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      OpenSearch Vector Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OpenSearch Vector Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-architecture-components" class="md-nav__link">
    <span class="md-ellipsis">
      Core Architecture Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-management-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Management Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#engine-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Engine Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#index-configuration-and-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Index Configuration and Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Index Configuration and Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-vector-field-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Vector Field Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hnsw-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      HNSW Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ivf-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      IVF Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-vector-field-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Vector Field Configuration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reranking-in-opensearch" class="md-nav__link">
    <span class="md-ellipsis">
      Reranking in OpenSearch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reranking in OpenSearch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-rescoring-with-opensearch" class="md-nav__link">
    <span class="md-ellipsis">
      Native Rescoring with OpenSearch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-function-scoring" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Function Scoring
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hybrid-search-with-reranking" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Search with Reranking
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#external-neural-reranking-integration" class="md-nav__link">
    <span class="md-ellipsis">
      External Neural Reranking Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iv-advanced-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Part IV: Advanced Applications
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part IV: Advanced Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-modal-search" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-modal Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-modal Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-multi-modal-vector-search" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Multi-Modal Vector Search
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-modal-search-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Cross-Modal Search Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#-performance-metrics-disclaimer" class="md-nav__link">
    <span class="md-ellipsis">
      ⚠️ Performance Metrics Disclaimer
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../opensearch_productionize/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deployment Options
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../kendra_vs_opensearch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    OpenSearch vs Kendra
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../opensearch_vs_pinecone/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    OpenSearch vs PineCone
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../search_examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    README
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../LICENSE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LICENSE
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-i-search-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Part I: Search Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part I: Search Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#traditional-text-based-search" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional Text-Based Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Traditional Text-Based Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-evolution-of-keyword-search" class="md-nav__link">
    <span class="md-ellipsis">
      The Evolution of Keyword Search
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bm25-the-modern-standard" class="md-nav__link">
    <span class="md-ellipsis">
      BM25: The Modern Standard
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#where-text-search-excels" class="md-nav__link">
    <span class="md-ellipsis">
      Where Text Search Excels
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limitations-of-text-based-search" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations of Text-Based Search
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-search-evolution" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Search Evolution
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vector Search Evolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-semantic-understanding-breakthrough" class="md-nav__link">
    <span class="md-ellipsis">
      The Semantic Understanding Breakthrough
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-search-addresses-text-search-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Search Addresses Text Search Limitations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-mathematics-of-semantic-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      The Mathematics of Semantic Similarity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#search-approach-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Search Approach Comparison
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Search Approach Comparison">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#detailed-comparison-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Detailed Comparison Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehensive-decision-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Decision Framework
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-progression-text-vector-hybrid_1" class="md-nav__link">
    <span class="md-ellipsis">
      The Progression: Text → Vector → Hybrid
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Progression: Text → Vector → Hybrid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hybrid-search-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Search Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#real-world-hybrid-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Real-World Hybrid Examples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Strategy
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reranking-refining-search-results" class="md-nav__link">
    <span class="md-ellipsis">
      Reranking: Refining Search Results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reranking: Refining Search Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-two-stage-search-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      The Two-Stage Search Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-reranking-is-essential" class="md-nav__link">
    <span class="md-ellipsis">
      Why Reranking is Essential
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-reranking-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Reranking Approaches
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Approaches
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-ii-vector-search-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Part II: Vector Search Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part II: Vector Search Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#high-dimensional-geometry-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      High-Dimensional Geometry Challenges
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#similarity-metrics-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Similarity Metrics Deep Dive
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#approximate-nearest-neighbor-ann-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Approximate Nearest Neighbor (ANN) Algorithms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hnsw-hierarchical-navigable-small-world" class="md-nav__link">
    <span class="md-ellipsis">
      HNSW: Hierarchical Navigable Small World
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HNSW: Hierarchical Navigable Small World">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conceptual-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Conceptual Understanding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-parameter-analysis-and-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Parameter Analysis and Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#real-world-performance-characteristics" class="md-nav__link">
    <span class="md-ellipsis">
      Real-World Performance Characteristics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ivf-inverted-file-index" class="md-nav__link">
    <span class="md-ellipsis">
      IVF: Inverted File Index
    </span>
  </a>
  
    <nav class="md-nav" aria-label="IVF: Inverted File Index">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conceptual-foundation-and-mathematical-intuition" class="md-nav__link">
    <span class="md-ellipsis">
      Conceptual Foundation and Mathematical Intuition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-ivf-techniques-and-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced IVF Techniques and Optimizations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#product-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Product Quantization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Product Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conceptual-understanding-and-mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Conceptual Understanding and Mathematical Foundation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-selection-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm Selection Guide
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Algorithm Selection Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#comprehensive-decision-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Decision Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-specific-optimization-guidelines" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm-Specific Optimization Guidelines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hybrid-algorithm-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Algorithm Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iii-opensearch-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Part III: OpenSearch Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part III: OpenSearch Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#opensearch-vector-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      OpenSearch Vector Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OpenSearch Vector Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-architecture-components" class="md-nav__link">
    <span class="md-ellipsis">
      Core Architecture Components
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-management-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Management Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#engine-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Engine Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#index-configuration-and-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Index Configuration and Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Index Configuration and Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-vector-field-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Vector Field Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hnsw-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      HNSW Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ivf-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      IVF Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-vector-field-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Vector Field Configuration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reranking-in-opensearch" class="md-nav__link">
    <span class="md-ellipsis">
      Reranking in OpenSearch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reranking in OpenSearch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-rescoring-with-opensearch" class="md-nav__link">
    <span class="md-ellipsis">
      Native Rescoring with OpenSearch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-function-scoring" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Function Scoring
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hybrid-search-with-reranking" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Search with Reranking
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#external-neural-reranking-integration" class="md-nav__link">
    <span class="md-ellipsis">
      External Neural Reranking Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iv-advanced-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Part IV: Advanced Applications
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part IV: Advanced Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-modal-search" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-modal Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-modal Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-multi-modal-vector-search" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Multi-Modal Vector Search
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-modal-search-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Cross-Modal Search Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#-performance-metrics-disclaimer" class="md-nav__link">
    <span class="md-ellipsis">
      ⚠️ Performance Metrics Disclaimer
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="opensearch-theory-to-implementation">OpenSearch: Theory to Implementation<a class="headerlink" href="#opensearch-theory-to-implementation" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>A comprehensive guide to understanding and implementing modern search systems, from traditional text-based approaches to advanced vector search algorithms and their practical implementation in OpenSearch.</p>
<h2 id="part-i-search-approaches">Part I: Search Approaches<a class="headerlink" href="#part-i-search-approaches" title="Permanent link">&para;</a></h2>
<p>Search systems have evolved dramatically over the past decades, from simple keyword matching to sophisticated semantic understanding. This evolution reflects our growing need to find relevant information in increasingly large and diverse datasets. Understanding different search approaches—their strengths, limitations, and ideal use cases—is essential for building effective search systems.</p>
<h3 id="traditional-text-based-search">Traditional Text-Based Search<a class="headerlink" href="#traditional-text-based-search" title="Permanent link">&para;</a></h3>
<p>Text-based search has been the cornerstone of information retrieval for decades. Understanding its mechanisms, strengths, and limitations provides crucial context for why vector search emerged and when each approach excels.</p>
<h4 id="the-evolution-of-keyword-search">The Evolution of Keyword Search<a class="headerlink" href="#the-evolution-of-keyword-search" title="Permanent link">&para;</a></h4>
<p><strong>Early Days: Simple Keyword Matching</strong></p>
<p>The earliest search systems operated on exact keyword matching - a document was relevant if it contained the search terms. This binary approach worked for small collections but failed to capture semantic meaning or handle variations in language.</p>
<p><strong>Statistical Revolution: TF-IDF</strong></p>
<p>Term Frequency-Inverse Document Frequency (<a href="../glossary/#tf-idf-term-frequency-inverse-document-frequency">TF-IDF</a>) introduced statistical sophistication to search by considering two key factors:</p>
<ul>
<li><strong>Term Frequency (TF):</strong> How often a term appears in a document</li>
<li><strong>Inverse Document Frequency (IDF):</strong> How rare or common a term is across the entire collection</li>
</ul>
<p>The intuition is powerful: terms that appear frequently in a specific document but rarely across the collection are likely more significant for that document's meaning.</p>
<p><strong>Mathematical Foundation of TF-IDF:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>TF-IDF(term, document) = TF(term, document) × IDF(term)
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>Where:
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>TF(term, document) = (Number of times term appears in document) / (Total terms in document)
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>IDF(term) = log(Total documents / Documents containing term)
</code></pre></div>
<p><strong>Example:</strong> </p>
<p>Consider searching for "machine learning" in a collection of 10,000 documents:</p>
<p>Document A: Contains "machine" 10 times out of 1,000 words, "learning" 8 times
"machine" appears in 3,000 documents, "learning" appears in 2,000 documents</p>
<ul>
<li>For "machine": TF = 10/1,000 = 0.01, IDF = log(10,000/3,000) = 0.52, TF-IDF = 0.0052</li>
<li>For "learning": TF = 8/1,000 = 0.008, IDF = log(10,000/2,000) = 0.70, TF-IDF = 0.0056</li>
</ul>
<p>The term "learning" scores higher despite lower frequency because it's rarer across the collection.</p>
<h4 id="bm25-the-modern-standard">BM25: The Modern Standard<a class="headerlink" href="#bm25-the-modern-standard" title="Permanent link">&para;</a></h4>
<p><strong>Best Matching 25 (BM25)</strong> represents the current gold standard for text relevance scoring, addressing TF-IDF's limitations through sophisticated normalization and parameter tuning.</p>
<p><strong>BM25 Formula:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>[BM25](./glossary.md#bm25-best-matching-25)(query, document) = Σ IDF(term) × (tf × (k1 + 1)) / (tf + k1 × (1 - b + b × |d|/avgdl))
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>Where:
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>- tf = term frequency in document
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>- |d| = document length in words
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>- avgdl = average document length in collection
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>- k1 = term frequency saturation parameter (typically 1.2-2.0)
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>- b = document length normalization parameter (typically 0.75)
</code></pre></div>
<p><strong>Key Improvements Over TF-IDF:</strong></p>
<ol>
<li>
<p><strong>Term Frequency Saturation:</strong> As term frequency increases, the contribution grows logarithmically rather than linearly, preventing keyword stuffing from dominating scores.</p>
</li>
<li>
<p><strong>Document Length Normalization:</strong> Longer documents don't automatically score higher simply due to containing more words. The parameter <code>b</code> controls how much document length affects scoring.</p>
</li>
<li>
<p><strong>Tunable Parameters:</strong> <code>k1</code> and <code>b</code> can be adjusted based on collection characteristics and user preferences.</p>
</li>
</ol>
<p><strong>Real-World Example:</strong></p>
<p>Consider searching for "sustainable energy solutions" across technical papers:</p>
<ul>
<li><em>Document A (500 words):</em> Contains "sustainable" 3 times, "energy" 5 times, "solutions" 2 times</li>
<li><em>Document B (2,000 words):</em> Contains "sustainable" 8 times, "energy" 12 times, "solutions" 6 times</li>
</ul>
<p>Traditional TF would favor Document B due to higher absolute term frequencies. BM25's length normalization ensures Document A isn't penalized for being concise, while term frequency saturation prevents Document B from dominating solely due to repetition.</p>
<h4 id="where-text-search-excels">Where Text Search Excels<a class="headerlink" href="#where-text-search-excels" title="Permanent link">&para;</a></h4>
<p><strong>Precision-Critical Scenarios:</strong></p>
<ul>
<li><strong>Legal Document Retrieval:</strong> Finding contracts containing specific clauses like "force majeure" or "intellectual property"</li>
<li><strong>Technical Documentation:</strong> Locating API references with exact method names like "getUserById()"</li>
<li><strong>Product Catalogs:</strong> Matching precise specifications like "iPhone 15 Pro Max 256GB Blue"</li>
</ul>
<p><strong>Transparent Relevance:</strong></p>
<p>Users can easily understand why results matched their query. When searching for "Python pandas DataFrame," it's clear that documents containing these exact terms are relevant. This transparency builds user trust and enables query refinement.</p>
<p><strong>Computational Efficiency:</strong></p>
<p>Text search operations are computationally lightweight:
- Index creation: O(N × M) where N = documents, M = average document length
- Query processing: O(log N) for term lookups plus scoring
- Memory requirements: Modest inverted index storage</p>
<p><strong>Query Flexibility:</strong></p>
<ul>
<li><strong>Boolean Operators:</strong> "machine learning" AND "Python" NOT "R"</li>
<li><strong>Phrase Matching:</strong> "artificial intelligence" (exact phrase)</li>
<li><strong>Wildcards:</strong> "comput*" (matches compute, computer, computing)</li>
<li><strong>Field-Specific:</strong> title:"AI" OR content:"machine learning"</li>
</ul>
<h4 id="limitations-of-text-based-search">Limitations of Text-Based Search<a class="headerlink" href="#limitations-of-text-based-search" title="Permanent link">&para;</a></h4>
<p><strong>The Vocabulary Mismatch Problem:</strong></p>
<p>Text search fails when users and documents employ different terminology for the same concepts:</p>
<p><em>Query:</em> "car repair"
<em>Missed Documents:</em> "automobile maintenance," "vehicle servicing," "auto mechanic"</p>
<p>This fundamental limitation occurs because text search operates on exact string matching without understanding that "car," "automobile," and "vehicle" refer to the same concept.</p>
<p><strong>Context Insensitivity:</strong></p>
<p>The word "bank" could refer to:</p>
<ul>
<li>Financial institution</li>
<li>River bank</li>
<li>Memory bank (computing)</li>
<li>Blood bank</li>
</ul>
<p>Text search cannot distinguish between these contexts without additional semantic understanding.</p>
<p><strong>Language Barriers:</strong></p>
<p>Text search struggles with:</p>
<ul>
<li><strong>Synonyms:</strong> "happy" vs "joyful" vs "cheerful"</li>
<li><strong>Multilingual Content:</strong> English query missing Spanish documents with same meaning</li>
<li><strong>Acronyms and Abbreviations:</strong> "AI" vs "Artificial Intelligence"</li>
<li><strong>Misspellings:</strong> "recieve" vs "receive"</li>
</ul>
<p><strong>Query Formulation Challenges:</strong></p>
<p>Users often struggle to formulate effective keyword queries:</p>
<ul>
<li><strong>Conceptual Queries:</strong> "companies similar to Netflix" (user wants concept similarity, not exact matches)</li>
<li><strong>Natural Language:</strong> "best laptop for college students under $800" (contains intent and constraints)</li>
<li><strong>Exploratory Search:</strong> "new developments in renewable energy" (seeking discovery, not specific documents)</li>
</ul>
<h3 id="vector-search-evolution">Vector Search Evolution<a class="headerlink" href="#vector-search-evolution" title="Permanent link">&para;</a></h3>
<p>Vector search emerged to address the fundamental limitations of text-based search by representing content and queries as mathematical vectors in high-dimensional semantic space.</p>
<h4 id="the-semantic-understanding-breakthrough">The Semantic Understanding Breakthrough<a class="headerlink" href="#the-semantic-understanding-breakthrough" title="Permanent link">&para;</a></h4>
<p><strong>From Keywords to Meaning:</strong></p>
<p>Vector search transforms the paradigm from "what words are present?" to "what does this mean?" By converting text into dense numerical vectors, semantically similar content produces geometrically similar vectors, regardless of exact wording.</p>
<p><strong>The Embedding Revolution:</strong></p>
<p>Modern <a href="../glossary/#embedding">embedding</a> models, trained on vast text corpora, learn to represent concepts in continuous vector spaces where:
- Similar meanings cluster together
- Relationships become mathematical operations
- Context determines representation</p>
<p><strong>Example Transformation:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>Traditional Keyword Index:
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>&quot;dog&quot; → Document IDs: [1, 5, 23, 67]
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>&quot;puppy&quot; → Document IDs: [12, 45, 89]
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>&quot;canine&quot; → Document IDs: [3, 34, 78]
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>Vector Representation:
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>&quot;dog&quot; → [0.2, -0.1, 0.8, 0.3, ..., 0.5]
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>&quot;puppy&quot; → [0.3, -0.2, 0.7, 0.4, ..., 0.6] (geometrically close to &quot;dog&quot;)
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>&quot;canine&quot; → [0.1, -0.3, 0.9, 0.2, ..., 0.4] (also close to &quot;dog&quot;)
</code></pre></div>
<h4 id="how-vector-search-addresses-text-search-limitations">How Vector Search Addresses Text Search Limitations<a class="headerlink" href="#how-vector-search-addresses-text-search-limitations" title="Permanent link">&para;</a></h4>
<p><strong>Solving Vocabulary Mismatch:</strong></p>
<p>Vector search naturally handles synonyms and related concepts because embedding models learn that different words with similar meanings should have similar representations.</p>
<p><em>Query Vector:</em> "automobile maintenance"
<em>Matches:</em> Documents about "car repair," "vehicle servicing," "auto mechanic"</p>
<p>The system finds these matches not through keyword overlap but through semantic similarity in vector space.</p>
<p><strong>Context-Aware Understanding:</strong></p>
<p>Advanced embedding models like <a href="../glossary/#bert-bidirectional-encoder-representations-from-transformers">BERT</a> and <a href="../glossary/#transformer">transformer</a>-based architectures consider context when generating vectors:</p>
<ul>
<li>"The bank approved my loan" → Vector emphasizing financial context</li>
<li>"I sat by the river bank" → Vector emphasizing geographical/nature context</li>
</ul>
<p>These contextual embeddings enable more precise semantic matching.</p>
<p><strong>Cross-Language Capabilities:</strong></p>
<p>Multilingual embedding models create shared semantic spaces across languages:</p>
<ul>
<li><em>English Query:</em> "machine learning algorithms"</li>
<li><em>Spanish Match:</em> "algoritmos de aprendizaje automático"</li>
<li><em>French Match:</em> "algorithmes d'apprentissage automatique"</li>
</ul>
<p>All three phrases map to similar regions in vector space, enabling cross-language search without translation.</p>
<p><strong>Natural Language Query Handling:</strong></p>
<p>Vector search excels with conversational, intent-driven queries:</p>
<ul>
<li><em>Query:</em> "best affordable laptops for college students"</li>
<li><em>Understanding:</em> The vector captures concepts of "budget-friendly," "portable computers," "educational use," "student needs"</li>
<li><em>Matches:</em> Reviews, comparisons, and recommendations that discuss these concepts even without exact keywords</li>
</ul>
<h4 id="the-mathematics-of-semantic-similarity">The Mathematics of Semantic Similarity<a class="headerlink" href="#the-mathematics-of-semantic-similarity" title="Permanent link">&para;</a></h4>
<p><strong>High-Dimensional Semantic Space:</strong></p>
<p>Embedding models typically generate vectors with 384 to 1,536 dimensions. Each dimension captures different aspects of meaning:</p>
<ul>
<li>Dimension 127: Might encode "technology-related" concepts</li>
<li>Dimension 445: Might capture "positive sentiment"</li>
<li>Dimension 892: Might represent "temporal aspects"</li>
</ul>
<p><strong>Similarity Metrics:</strong></p>
<p>The choice of similarity metric affects search behavior:</p>
<p><strong><a href="../glossary/#cosine-similarity">Cosine Similarity</a> (Most Common):</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>cosine_similarity(A, B) = (A · B) / (||A|| × ||B||)
</code></pre></div>
<ul>
<li>Measures angle between vectors, ignoring magnitude</li>
<li>Range: -1 (opposite) to 1 (identical)</li>
<li>Best for text where length doesn't indicate semantic importance</li>
</ul>
<p><strong>Example:</strong> Two product reviews might have different lengths but similar sentiment and topics. Cosine similarity focuses on the semantic direction rather than the "intensity" of the review.</p>
<h3 id="search-approach-comparison">Search Approach Comparison<a class="headerlink" href="#search-approach-comparison" title="Permanent link">&para;</a></h3>
<p>Understanding when to use text search versus vector search—and how to combine them effectively—is crucial for building optimal search systems.</p>
<h4 id="detailed-comparison-framework">Detailed Comparison Framework<a class="headerlink" href="#detailed-comparison-framework" title="Permanent link">&para;</a></h4>
<p><strong><a href="../glossary/#precision">Precision</a> vs <a href="../glossary/#recall">Recall</a> Trade-offs:</strong></p>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Text Search</th>
<th>Vector Search</th>
<th>Winner</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Exact product lookup</strong></td>
<td>"MacBook Pro M3 16GB" → Perfect match</td>
<td>May find similar products</td>
<td><strong>Text Search</strong></td>
</tr>
<tr>
<td><strong>Concept exploration</strong></td>
<td>"sustainable energy" → Only exact phrase</td>
<td>Finds renewable, green, clean energy</td>
<td><strong>Vector Search</strong></td>
</tr>
<tr>
<td><strong>Technical specifications</strong></td>
<td>"RAM &gt;= 16GB AND SSD" → Precise filtering</td>
<td>Cannot handle logical constraints</td>
<td><strong>Text Search</strong></td>
</tr>
<tr>
<td><strong>Intent-based queries</strong></td>
<td>"best laptop for programming" → Keyword luck</td>
<td>Understands programming needs</td>
<td><strong>Vector Search</strong></td>
</tr>
</tbody>
</table>
<p><strong>Performance Characteristics:</strong></p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Text Search</th>
<th>Vector Search</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Index Build Time</strong></td>
<td>Minutes</td>
<td>Hours (embedding generation)</td>
</tr>
<tr>
<td><strong>Query <a href="../glossary/#latency">Latency</a></strong></td>
<td>&lt;1ms</td>
<td>1-100ms (depending on algorithm)</td>
</tr>
<tr>
<td><strong><a href="../glossary/#memory-usage">Memory Usage</a></strong></td>
<td>Low (inverted index)</td>
<td>High (vector storage)</td>
</tr>
<tr>
<td><strong>Accuracy</strong></td>
<td>Perfect for keywords</td>
<td>85-99% approximate</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>Excellent</td>
<td>Good (with proper algorithms)</td>
</tr>
</tbody>
</table>
<h4 id="comprehensive-decision-framework">Comprehensive Decision Framework<a class="headerlink" href="#comprehensive-decision-framework" title="Permanent link">&para;</a></h4>
<p><em>Understanding when to employ text search versus vector search requires analyzing multiple dimensions of your search requirements. The following framework provides detailed guidance for making informed architectural decisions.</em></p>
<p><strong>Use Text Search When:</strong></p>
<p><strong>Exact Matching is Critical</strong></p>
<ul>
<li>Legal document retrieval: "habeas corpus," "force majeure"</li>
<li>Medical codes: "ICD-10 J44.0" (COPD diagnosis)</li>
<li>Product catalogs: "SKU-12345-RED-L"</li>
</ul>
<p><strong>Users Provide Specific Keywords</strong></p>
<ul>
<li>Technical documentation: "numpy.array.reshape()"</li>
<li>Database queries: "SELECT statement syntax"</li>
<li>API references: "REST POST /users endpoint"</li>
</ul>
<p><strong>Computational Resources are Limited</strong></p>
<ul>
<li>Mobile applications with limited processing power</li>
<li>Real-time systems requiring sub-millisecond responses</li>
<li>High-volume systems needing minimal infrastructure</li>
</ul>
<p><strong>Transparency and Explainability Required</strong></p>
<ul>
<li>Regulatory compliance scenarios where relevance must be explained</li>
<li>User interfaces showing why results matched</li>
<li>A/B testing where ranking factors need clear attribution</li>
</ul>
<p><strong>Use Vector Search When:</strong></p>
<p><strong>Semantic Understanding is Essential</strong></p>
<ul>
<li>Customer support: "my order hasn't arrived" → find shipping delay content</li>
<li>Research: "climate change impacts" → find global warming, environmental effects</li>
<li>Content discovery: "similar to The Matrix" → find sci-fi, cyberpunk themes</li>
</ul>
<p><strong>Cross-Language Search Needed</strong></p>
<ul>
<li>Global content platforms with multilingual documents</li>
<li>International e-commerce with product descriptions in multiple languages</li>
<li>Academic research across different language publications</li>
</ul>
<p><strong>Natural Language Queries Expected</strong></p>
<ul>
<li>Voice search: "What's a good Italian restaurant nearby?"</li>
<li>Conversational AI: "Show me articles about renewable energy policies"</li>
<li>Mobile search: "cheap flights to Europe next month"</li>
</ul>
<p><strong>Content Discovery and Exploration</strong></p>
<ul>
<li>Media recommendations: "movies like Inception"</li>
<li>News discovery: "stories related to artificial intelligence ethics"</li>
<li>Research paper suggestions: "papers citing similar methodologies"</li>
</ul>
<h3 id="the-progression-text-vector-hybrid_1">The Progression: Text → Vector → Hybrid<a class="headerlink" href="#the-progression-text-vector-hybrid_1" title="Permanent link">&para;</a></h3>
<p>Modern search systems increasingly adopt hybrid approaches that combine the precision of text search with the semantic understanding of vector search.</p>
<h4 id="hybrid-search-architecture">Hybrid Search Architecture<a class="headerlink" href="#hybrid-search-architecture" title="Permanent link">&para;</a></h4>
<p><strong>Score Combination Strategies:</strong></p>
<ol>
<li>
<p><strong>Linear Combination</strong>
   <div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>final_score = α × text_score + β × vector_score
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>Where α + β = 1, and weights can be tuned based on query type
</code></pre></div></p>
</li>
<li>
<p><strong>Rank Fusion</strong>
   <div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>RRF_score = Σ(1 / (k + rank_in_list))
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>Combines rankings from different search methods
</code></pre></div></p>
</li>
<li>
<p><strong>Learning-to-Rank</strong>
   Machine learning models that learn optimal score combination from user behavior data.</p>
</li>
</ol>
<h4 id="real-world-hybrid-examples">Real-World Hybrid Examples<a class="headerlink" href="#real-world-hybrid-examples" title="Permanent link">&para;</a></h4>
<p><strong>E-commerce Search:</strong></p>
<p><em>Query:</em> "wireless bluetooth headphones under $100"</p>
<ul>
<li><strong>Text Component:</strong> Finds products with exact specifications and price range</li>
<li><strong>Vector Component:</strong> Discovers products described as "cord-free audio devices," "wireless earbuds," "Bluetooth speakers"</li>
<li><strong>Combined Result:</strong> Comprehensive coverage including exact matches and semantically related products</li>
</ul>
<p><strong>Customer Support:</strong></p>
<p><em>Query:</em> "How do I reset my password?"</p>
<ul>
<li><strong>Text Component:</strong> Finds FAQ entries with exact phrase "reset password"</li>
<li><strong>Vector Component:</strong> Discovers related articles about "account recovery," "login issues," "forgotten credentials"</li>
<li><strong>Combined Result:</strong> Complete support coverage from exact matches to related topics</li>
</ul>
<p><strong>Academic Research:</strong></p>
<p><em>Query:</em> "deep learning applications in medical imaging"</p>
<ul>
<li><strong>Text Component:</strong> Papers explicitly mentioning these exact terms</li>
<li><strong>Vector Component:</strong> Research on "neural networks in radiology," "AI for diagnostic imaging," "machine learning in healthcare"</li>
<li><strong>Combined Result:</strong> Broader research landscape while maintaining precise topic focus</li>
</ul>
<h4 id="implementation-strategy">Implementation Strategy<a class="headerlink" href="#implementation-strategy" title="Permanent link">&para;</a></h4>
<p><strong>Query Classification:</strong></p>
<p>Intelligent systems can dynamically adjust the balance between text and vector search based on query characteristics:</p>
<ul>
<li><strong>Exact identifiers</strong> (SKUs, codes, names): 80% text, 20% vector weight</li>
<li><strong>Conceptual queries</strong> ("similar to," "like," "about"): 30% text, 70% vector weight</li>
<li><strong>Factual queries</strong> ("how to," "what is"): 60% text, 40% vector weight</li>
<li><strong>Default queries</strong>: 50% text, 50% vector weight (balanced approach)</li>
</ul>
<p><strong>User Interface Adaptation:</strong></p>
<p>Search interfaces can provide different experiences based on the search approach:</p>
<ul>
<li><strong>Text-heavy results:</strong> Show keyword highlighting, exact matches, filters</li>
<li><strong>Vector-heavy results:</strong> Display "because you searched for," related concepts, exploration suggestions</li>
<li><strong>Hybrid results:</strong> Combine both approaches with clear result categorization</li>
</ul>
<h3 id="reranking-refining-search-results">Reranking: Refining Search Results<a class="headerlink" href="#reranking-refining-search-results" title="Permanent link">&para;</a></h3>
<p>While initial retrieval systems (text search, vector search, or hybrid approaches) excel at quickly identifying potentially relevant candidates from large datasets, they often lack the computational resources to perform deep analysis of each result. <strong>Reranking</strong> addresses this limitation by applying sophisticated scoring models to a smaller set of initial results, dramatically improving relevance and user satisfaction.</p>
<h4 id="the-two-stage-search-architecture">The Two-Stage Search Architecture<a class="headerlink" href="#the-two-stage-search-architecture" title="Permanent link">&para;</a></h4>
<p><strong>Stage 1: Fast Retrieval (Recall-Focused)</strong>
- Primary goal: Cast a wide net to capture potentially relevant content
- Algorithms: BM25, HNSW, IVF, or hybrid combinations
- Speed: Optimized for millisecond response times
- Scope: Search entire corpus (millions to billions of documents)</p>
<p><strong>Stage 2: Precise Reranking (Precision-Focused)</strong></p>
<ul>
<li>Primary goal: Apply sophisticated relevance modeling to refine rankings</li>
<li>Algorithms: Cross-encoders, learning-to-rank, neural rerankers</li>
<li>Speed: More computationally intensive but applied to fewer candidates</li>
<li>Scope: Rerank top 100-1000 candidates from Stage 1</li>
</ul>
<h4 id="why-reranking-is-essential">Why Reranking is Essential<a class="headerlink" href="#why-reranking-is-essential" title="Permanent link">&para;</a></h4>
<p><strong>Computational Trade-offs in Search:</strong></p>
<p>Initial retrieval systems face a fundamental constraint: they must balance speed with accuracy across massive datasets. A brute-force approach applying sophisticated relevance modeling to every document would be computationally prohibitive.</p>
<p><em>Example: E-commerce Search</em></p>
<ul>
<li><strong>Without Reranking:</strong> Fast keyword/vector search returns "wireless headphones" but may rank by basic relevance signals</li>
<li><strong>With Reranking:</strong> Additional factors like user preferences, product ratings, price sensitivity, and seasonal trends refine the ranking</li>
</ul>
<p><strong>Quality Improvements:</strong></p>
<p>Reranking typically improves key search metrics:
- <strong>NDCG@10:</strong> 15-30% improvement in ranking quality
- <strong>Click-through Rate:</strong> 10-25% increase in user engagement
- <strong>Conversion Rate:</strong> 5-15% improvement in e-commerce scenarios</p>
<h4 id="types-of-reranking-approaches">Types of Reranking Approaches<a class="headerlink" href="#types-of-reranking-approaches" title="Permanent link">&para;</a></h4>
<p><strong>Cross-Encoder Reranking:</strong></p>
<p>Cross-encoders jointly encode the query and each candidate document, enabling rich interaction modeling that captures nuanced relevance signals impossible in the initial retrieval stage.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>Architecture:
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>Query: &quot;best wireless headphones for running&quot;
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>Candidate: &quot;Sony WH-1000XM5 Noise Canceling Headphones&quot;
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>Cross-Encoder Input: [CLS] best wireless headphones for running [SEP] Sony WH-1000XM5 Noise Canceling Headphones - Premium noise canceling... [SEP]
</code></pre></div>
<p><strong>Learning-to-Rank (LTR):</strong></p>
<p>Machine learning models trained on historical user interactions, combining multiple relevance features to optimize ranking metrics directly.</p>
<p><em>Feature Categories:</em></p>
<ul>
<li>Query-document similarity scores</li>
<li>User interaction signals (clicks, dwell time)</li>
<li>Document quality indicators (freshness, authority)</li>
<li>Contextual factors (time, location, device)</li>
</ul>
<p><strong>Neural Reranking Models:</strong></p>
<p>Advanced transformer-based models that can capture complex semantic relationships and user intent patterns beyond traditional relevance matching.</p>
<h4 id="implementation-approaches">Implementation Approaches<a class="headerlink" href="#implementation-approaches" title="Permanent link">&para;</a></h4>
<p>Reranking can be implemented through various approaches depending on your search infrastructure:</p>
<p><strong>Native Search Engine Integration:</strong>
- Use built-in rescoring capabilities (OpenSearch <code>rescore</code>, Elasticsearch rescoring)
- Leverage function scoring and custom ranking algorithms
- Integrate machine learning models directly into the search pipeline</p>
<p><strong>External Reranking Services:</strong>
- Microservice architecture with dedicated reranking endpoints
- Post-processing pipeline that refines initial search results
- Real-time model serving for neural reranking</p>
<p><strong>Hybrid Approaches:</strong>
- Combine multiple reranking stages (rule-based → ML-based → neural)
- Use different reranking intensity based on query characteristics
- Implement fallback strategies for high-load scenarios</p>
<p><em>For specific OpenSearch implementation examples and configurations, see <a href="#reranking-in-opensearch">Reranking in OpenSearch</a> in Part III.</em></p>
<h4 id="performance-considerations">Performance Considerations<a class="headerlink" href="#performance-considerations" title="Permanent link">&para;</a></h4>
<p><strong>Latency Impact:</strong>
- Initial retrieval: 5-20ms
- Reranking overhead: 10-50ms additional
- Total query time: 15-70ms (still well within acceptable limits)</p>
<p><strong>Resource Usage:</strong>
- Reranking models require additional compute resources
- GPU acceleration recommended for neural rerankers
- Memory usage scales with reranking window size</p>
<p><strong>Scalability Strategies:</strong>
- <strong>Async Reranking:</strong> Return initial results immediately, update with reranked results
- <strong>Cached Reranking:</strong> Cache reranked results for popular queries
- <strong>Tiered Reranking:</strong> Apply different reranking intensity based on query importance</p>
<hr />
<h2 id="part-ii-vector-search-algorithms">Part II: Vector Search Algorithms<a class="headerlink" href="#part-ii-vector-search-algorithms" title="Permanent link">&para;</a></h2>
<h3 id="mathematical-foundations">Mathematical Foundations<a class="headerlink" href="#mathematical-foundations" title="Permanent link">&para;</a></h3>
<p>Vector search algorithms operate in high-dimensional spaces where traditional intuitions about distance and similarity often break down. Understanding these mathematical foundations is essential for selecting appropriate algorithms and tuning their parameters effectively.</p>
<h4 id="high-dimensional-geometry-challenges">High-Dimensional Geometry Challenges<a class="headerlink" href="#high-dimensional-geometry-challenges" title="Permanent link">&para;</a></h4>
<p><strong>The <a href="../glossary/#curse-of-dimensionality">Curse of Dimensionality</a>:</strong></p>
<p>As vector dimensions increase beyond ~100, several mathematical phenomena fundamentally change how search algorithms must operate:</p>
<p><strong>1. Distance Concentration</strong></p>
<p>In high-dimensional spaces, the difference between the nearest and farthest points becomes negligible relative to the absolute distances. This means naive distance calculations become less discriminative.</p>
<p><em>Mathematical Intuition:</em> Consider random points in a hypersphere. As dimensions increase:</p>
<ul>
<li>All points concentrate near the surface</li>
<li>Distances between any two points become approximately equal</li>
<li>Traditional distance-based nearest neighbor search loses effectiveness</li>
</ul>
<p><strong>Example:</strong> In 1000-dimensional space, if the closest point is distance 10.0 and the farthest is distance 12.0, the difference (2.0) becomes insignificant for practical ranking purposes.</p>
<p><strong>2. Volume Distribution</strong></p>
<p>Most of a high-dimensional hypersphere's volume exists in a thin shell near its surface, making uniform sampling and clustering challenging.</p>
<p><strong>3. Computational Complexity</strong></p>
<p>Brute-force search complexity grows as O(N × D) where N = number of vectors, D = dimensions:</p>
<ul>
<li>1M vectors × 768 dimensions = 768M calculations per query</li>
<li>At 1B operations/second: 0.768 seconds per query</li>
<li>For 100 QPS: requires 76.8 seconds of CPU time per second (impossible!)</li>
</ul>
<h4 id="similarity-metrics-deep-dive">Similarity Metrics Deep Dive<a class="headerlink" href="#similarity-metrics-deep-dive" title="Permanent link">&para;</a></h4>
<p><strong>Cosine Similarity: The Text Search Standard</strong></p>
<p>Cosine similarity measures the angle between vectors, making it ideal for text embeddings where magnitude often relates to document length rather than semantic importance.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>cosine_similarity(A, B) = (A · B) / (||A|| × ||B||)
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>Geometric Interpretation:
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>- cos(0°) = 1.0    (identical direction)
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>- cos(45°) = 0.707 (moderate similarity)
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>- cos(90°) = 0.0   (orthogonal, unrelated)
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>- cos(180°) = -1.0 (opposite meaning)
</code></pre></div>
<p><strong>Why Cosine Works for Text:</strong></p>
<p>Consider two movie reviews:</p>
<ul>
<li>Review A (short): "Great movie, excellent acting" → Vector magnitude: 5.2</li>
<li>Review B (long): "This film represents an outstanding achievement in cinematic excellence with superb performances..." → Vector magnitude: 12.8</li>
</ul>
<p>Both reviews express positive sentiment about acting quality. Cosine similarity focuses on the semantic direction (positive sentiment + acting praise) while ignoring the length difference.</p>
<p><strong><a href="../glossary/#euclidean-distance-l2">Euclidean Distance (L2)</a>: When Magnitude Matters</strong></p>
<p>Euclidean distance measures straight-line distance in vector space, treating all dimensions equally:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>euclidean_distance(A, B) = √(Σ(Aᵢ - Bᵢ)²)
</code></pre></div>
<p><strong>When to Use Euclidean:</strong></p>
<ul>
<li><strong>Image embeddings:</strong> Where color intensity, brightness, and other magnitude-based features matter</li>
<li><strong>Sensor data:</strong> Where absolute values carry meaning (temperature, pressure readings)</li>
<li><strong>Normalized embeddings:</strong> When all vectors are pre-normalized to unit length</li>
</ul>
<p><strong>Example:</strong> Comparing product images where a bright red dress should be more similar to a bright red shirt than to a dark red dress, Euclidean distance preserves these intensity relationships.</p>
<p><strong><a href="../glossary/#manhattan-distance-l1">Manhattan Distance (L1)</a>: Robustness in High Dimensions</strong></p>
<p>Manhattan distance sums absolute differences along each dimension:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>manhattan_distance(A, B) = Σ|Aᵢ - Bᵢ|
</code></pre></div>
<p><strong>Advantages in High Dimensions:</strong></p>
<ul>
<li>Less sensitive to outliers in individual dimensions</li>
<li>More stable in sparse vector spaces</li>
<li>Computationally efficient (no squaring operations)</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Sparse embeddings where many dimensions are zero</li>
<li>Categorical data encoded as vectors</li>
<li>Situations where dimension independence is important</li>
</ul>
<h4 id="approximate-nearest-neighbor-ann-algorithms">Approximate Nearest Neighbor (ANN) Algorithms<a class="headerlink" href="#approximate-nearest-neighbor-ann-algorithms" title="Permanent link">&para;</a></h4>
<p>The mathematical challenge of high-dimensional search drives the need for approximate algorithms that trade small accuracy losses for massive speed improvements.</p>
<p><strong>The Approximation Trade-off:</strong></p>
<ul>
<li><strong>Exact search:</strong> Guarantees finding the true nearest neighbors but computationally expensive</li>
<li><strong>Approximate search:</strong> Finds "good enough" neighbors (95-99% accuracy) at 10-1000× speed improvement</li>
</ul>
<p><strong>Quality Metrics:</strong></p>
<ul>
<li><strong><a href="../glossary/#recallk">Recall@K</a>:</strong> Percentage of true top-k neighbors found by the algorithm</li>
<li><strong>Query time:</strong> Milliseconds per search operation</li>
<li><strong>Index size:</strong> Memory required to store the search structure</li>
</ul>
<p>The goal is maximizing recall while minimizing query time and memory usage.</p>
<h3 id="hnsw-hierarchical-navigable-small-world">HNSW: Hierarchical Navigable Small World<a class="headerlink" href="#hnsw-hierarchical-navigable-small-world" title="Permanent link">&para;</a></h3>
<p><a href="../glossary/#hnsw-hierarchical-navigable-small-world">HNSW (Hierarchical Navigable Small World)</a> represents one of the most sophisticated and widely-adopted algorithms for approximate nearest neighbor search. It constructs a multi-layer graph structure that elegantly balances search speed and accuracy by exploiting the hierarchical navigation principles found in both social networks and geographical systems.</p>
<h4 id="conceptual-understanding">Conceptual Understanding<a class="headerlink" href="#conceptual-understanding" title="Permanent link">&para;</a></h4>
<p><strong>The Small World Phenomenon in Vector Space</strong></p>
<p>The algorithm draws inspiration from Stanley Milgram's famous "six degrees of separation" experiment, which demonstrated that any two people in the world are connected through an average of six social connections. HNSW applies this principle to high-dimensional vector search by creating multiple layers of connectivity that enable efficient navigation.</p>
<p><strong>Multi-Scale Navigation Analogy:</strong></p>
<p>Consider how you might navigate from New York to a specific address in Tokyo:</p>
<ol>
<li><strong>Global Scale (Layer 2):</strong> Use intercontinental connections - direct flight from JFK to Narita Airport</li>
<li><strong>Regional Scale (Layer 1):</strong> Use regional transportation - train from Narita to Tokyo city center</li>
<li><strong>Local Scale (Layer 0):</strong> Use local navigation - walking directions to the specific building</li>
</ol>
<p>HNSW mirrors this hierarchical approach in vector space:</p>
<ul>
<li><strong>Top Layers (2, 3, 4...):</strong> Sparse networks with long-distance "highways" connecting distant regions of vector space</li>
<li><strong>Middle Layers (1):</strong> Regional connections that bridge local neighborhoods</li>
<li><strong>Bottom Layer (0):</strong> Dense local neighborhoods where every point connects to its immediate neighbors</li>
</ul>
<p><strong>Graph Construction Philosophy:</strong></p>
<p><em>Probabilistic Hierarchy:</em> Rather than deterministically assigning nodes to layers, HNSW uses probabilistic assignment where each node has a decreasing probability of existing in higher layers. This creates a natural hierarchy where:</p>
<ul>
<li><strong>Layer 0:</strong> Contains all vectors (100% density)</li>
<li><strong>Layer 1:</strong> Contains ~50% of vectors</li>
<li><strong>Layer 2:</strong> Contains ~25% of vectors</li>
<li><strong>Layer L:</strong> Contains ~(1/2)^L percentage of vectors</li>
</ul>
<p><em>Connectivity Strategy:</em> Each node connects to its M nearest neighbors within each layer it participates in. This ensures that:
- Higher layers provide "express routes" across large distances
- Lower layers provide detailed local connectivity
- Navigation remains efficient at every scale</p>
<p><strong>Why This Architecture Works:</strong></p>
<ol>
<li>
<p><strong>Logarithmic Scaling:</strong> Search complexity scales as O(log N) rather than O(N), making it practical for massive datasets</p>
</li>
<li>
<p><strong>Greedy Search Efficiency:</strong> At each layer, greedy local search quickly moves toward the target region, with higher layers providing faster convergence</p>
</li>
<li>
<p><strong>Fault Tolerance:</strong> Multiple paths exist between any two points, making the structure robust against locally poor connections</p>
</li>
<li>
<p><strong>Memory Locality:</strong> Dense connections in lower layers ensure good cache performance during the final precise search phase</p>
</li>
</ol>
<h4 id="mathematical-foundation">Mathematical Foundation<a class="headerlink" href="#mathematical-foundation" title="Permanent link">&para;</a></h4>
<p><strong>Layer Assignment Probability:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>P(node reaches layer l) = (1/2)^l
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>Expected maximum layer: floor(-ln(uniform(0,1)) × mL)
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>where mL = 1/ln(2) ≈ 1.44
</code></pre></div>
<p>This probability distribution creates the hierarchical structure automatically:</p>
<ul>
<li>~50% of nodes only in layer 0</li>
<li>~25% reach layer 1</li>
<li>~12.5% reach layer 2</li>
<li>And so on...</li>
</ul>
<p><strong>Detailed Search Algorithm Mechanics:</strong></p>
<p><em>Phase 1: Global Navigation (Top Layers)</em></p>
<ol>
<li><strong>Entry Point Selection:</strong> Begin at the designated entry point in the highest layer</li>
<li><strong>Greedy Descent:</strong> At each layer, perform greedy search to find the local minimum</li>
<li>Calculate distances from current position to all connected neighbors</li>
<li>Move to the neighbor with smallest distance to query vector</li>
<li>Repeat until no neighbor is closer than current position</li>
<li><strong>Layer Transition:</strong> Use the final position as the starting point for the next layer down</li>
</ol>
<p><em>Phase 2: Precision Navigation (Bottom Layer)</em></p>
<ol>
<li><strong>Beam Search Expansion:</strong> Instead of simple greedy search, maintain a candidate set of size ef_search</li>
<li><strong>Dynamic Candidate Management:</strong></li>
<li>Track the ef_search closest points found so far</li>
<li>Explore neighbors of all candidates in the current beam</li>
<li>Update beam with newly discovered closer points</li>
<li><strong>Termination:</strong> Stop when no new candidates improve the current best set</li>
</ol>
<p><strong>Mathematical Intuition Behind Effectiveness:</strong></p>
<p><em>Logarithmic Layer Reduction:</em> With each layer containing approximately half the nodes of the layer below, the search space reduces exponentially. For a dataset of N points:
- Layer L contains ~N/(2^L) points
- Maximum layer height ≈ log₂(N)
- Each layer reduces search complexity by ~50%</p>
<p><em>Greedy Search Optimality:</em> In well-connected graphs, greedy local search approaches global optimality because:
- High-dimensional spaces often exhibit convex-like properties in neighborhood structures
- Dense connectivity ensures multiple paths to any target region
- The hierarchical structure provides "shortcuts" that prevent local minima traps</p>
<p><em>Distance Concentration Benefits:</em> HNSW actually leverages the curse of dimensionality:
- In high dimensions, most points are roughly equidistant from any query
- This makes the hierarchical approach more effective because "long jumps" in upper layers reliably move toward the target region
- Local refinement in lower layers exploits the small differences that matter for final ranking</p>
<h4 id="advanced-parameter-analysis-and-optimization">Advanced Parameter Analysis and Optimization<a class="headerlink" href="#advanced-parameter-analysis-and-optimization" title="Permanent link">&para;</a></h4>
<p><em>HNSW's performance characteristics are highly dependent on proper parameter selection. Understanding the mathematical relationships between parameters enables optimal configuration for specific use cases.</em></p>
<p><strong>M (Maximum Connections per Node)</strong></p>
<p>The M parameter fundamentally affects the graph's connectivity and search performance:</p>
<p><strong>Low M (8-16):</strong></p>
<ul>
<li><strong>Advantages:</strong> Lower memory usage, faster construction</li>
<li><strong>Disadvantages:</strong> Potential for disconnected regions, lower recall</li>
<li><strong>Use case:</strong> Memory-constrained environments, simple similarity patterns</li>
</ul>
<p><strong>Medium M (16-32):</strong></p>
<ul>
<li><strong>Advantages:</strong> Good balance of performance and memory</li>
<li><strong>Disadvantages:</strong> None significant for most applications</li>
<li><strong>Use case:</strong> General-purpose text search, balanced performance requirements</li>
</ul>
<p><strong>High M (32-64):</strong></p>
<ul>
<li><strong>Advantages:</strong> Excellent recall, robust against difficult data distributions</li>
<li><strong>Disadvantages:</strong> High memory usage, slower construction</li>
<li><strong>Use case:</strong> High-precision applications, complex high-dimensional data</li>
</ul>
<p><strong>Memory Calculation:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>Memory per node = M × 4 bytes (connection pointers) + vector storage
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>For 1M nodes, 384-dim vectors, M=24:
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>- Vector storage: 1M × 384 × 4 bytes = 1.54GB
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>- Graph connections: 1M × 24 × 4 bytes = 96MB
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>- System overhead: ~3-4GB total
</code></pre></div>
<p><strong>ef_construction (Construction Beam Width)</strong></p>
<p>Controls the trade-off between index quality and construction time:</p>
<p><strong>Low ef_construction (64-128):</strong></p>
<ul>
<li>Fast construction but potentially lower-quality graph</li>
<li>Risk of poor connections that hurt search recall</li>
<li>Suitable for development, rapid prototyping</li>
</ul>
<p><strong>Medium ef_construction (128-256):</strong></p>
<ul>
<li>Balanced approach for production systems</li>
<li>Good graph quality without excessive construction time</li>
<li>Recommended for most applications</li>
</ul>
<p><strong>High ef_construction (256-512+):</strong></p>
<ul>
<li>Highest quality graph structure</li>
<li>Slow construction but maximum search performance</li>
<li>Use when construction time is less critical than search quality</li>
</ul>
<p><strong>ef_search (Query-Time Beam Width)</strong></p>
<p>The only parameter tunable at query time, allowing dynamic performance adjustment:</p>
<p><strong>Performance Scaling:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>ef_search=10:  Ultra-fast, ~85% recall
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>ef_search=50:  Fast, ~95% recall
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>ef_search=100: Balanced, ~97% recall
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>ef_search=200: High accuracy, ~99% recall
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>ef_search=500: Near-perfect, ~99.5% recall
</code></pre></div>
<p><strong>Advanced Parameter Selection Strategies:</strong></p>
<p><em>Query-Adaptive ef_search:</em>
The ef_search parameter can be dynamically adjusted based on query characteristics and system load:</p>
<p><strong>Application-Specific Tuning:</strong></p>
<ul>
<li><strong>Real-time autocomplete:</strong> ef_search = 15-25 (ultra-low latency, 85-90% recall acceptable)</li>
<li><strong>Main search results:</strong> ef_search = 80-120 (balanced latency/accuracy for user-facing results)</li>
<li><strong>Recommendation systems:</strong> ef_search = 150-250 (higher accuracy for better user experience)</li>
<li><strong>Research/analytics:</strong> ef_search = 300-500 (maximum accuracy, latency less critical)</li>
<li><strong>Batch processing:</strong> ef_search = 200-400 (optimize for throughput over individual query speed)</li>
</ul>
<p><strong>System Load Adaptation:</strong></p>
<ul>
<li><strong>High load periods:</strong> Reduce ef_search to maintain response times</li>
<li><strong>Low load periods:</strong> Increase ef_search to improve result quality</li>
<li><strong>SLA-based scaling:</strong> Automatically adjust based on current system latency percentiles</li>
</ul>
<p><strong>Query Complexity Estimation:</strong></p>
<p>Some queries inherently require more exploration:</p>
<ul>
<li><strong>Outlier queries:</strong> Vectors far from typical data distribution need higher ef_search</li>
<li><strong>Ambiguous queries:</strong> Queries near decision boundaries between clusters benefit from broader search</li>
<li><strong>High-precision requirements:</strong> Critical applications (medical, financial) should use conservative (high) ef_search values</li>
</ul>
<h4 id="real-world-performance-characteristics">Real-World Performance Characteristics<a class="headerlink" href="#real-world-performance-characteristics" title="Permanent link">&para;</a></h4>
<p><strong>Scaling Behavior:</strong></p>
<p>HNSW performance scales favorably with dataset size:
- <strong>Construction time:</strong> O(N × log(N) × M × ef_construction)
- <strong>Search time:</strong> O(log(N) × ef_search)
- <strong>Memory usage:</strong> Linear with dataset size</p>
<p><strong>Construction Optimizations:</strong></p>
<p><strong>Parallel Construction:</strong> Distribute index building across multiple threads</p>
<ul>
<li>Partition vectors into chunks for concurrent processing</li>
<li>Use lock-free data structures for thread-safe updates</li>
<li>Typical speedup: 4-8x on modern multi-core systems</li>
</ul>
<p><strong>Progressive Construction:</strong> Build index incrementally for dynamic datasets</p>
<ul>
<li>Add new vectors without full reconstruction</li>
<li>Periodically rebalance for optimal performance</li>
<li>Essential for real-time applications</li>
</ul>
<p><strong>Memory-Mapped Storage:</strong> Handle datasets larger than RAM</p>
<ul>
<li>Store vectors in memory-mapped files</li>
<li>Let OS manage virtual memory and caching</li>
<li>Enables searching billion-scale datasets on modest hardware</li>
</ul>
<p><strong>Query-Time Optimizations:</strong></p>
<p><strong><a href="../glossary/#simd-single-instruction-multiple-data">SIMD</a> Vectorization:</strong> Accelerate distance calculations</p>
<ul>
<li>Use AVX2/AVX-512 instructions for parallel arithmetic</li>
<li>Achieve 4-16x speedup in distance computations</li>
<li>Critical for high-dimensional vectors (768, 1536 dimensions)</li>
</ul>
<p><strong>Batch Query Processing:</strong> Amortize overhead across multiple queries</p>
<ul>
<li>Process 10-100 queries simultaneously</li>
<li>Better CPU cache utilization</li>
<li>Improved memory bandwidth efficiency</li>
</ul>
<p><strong>Warm-up Strategies:</strong> Preload critical index regions</p>
<ul>
<li>Touch frequently accessed memory pages</li>
<li>Pre-compute entry points for different query types</li>
<li>Reduce cold-start latency in production systems</li>
</ul>
<p><strong>Memory Layout Optimizations:</strong></p>
<p><strong>Data Structure Packing:</strong> Minimize memory overhead</p>
<ul>
<li>Pack connection lists efficiently</li>
<li>Use compact representations for small M values</li>
<li>Typical overhead reduction: 20-40%</li>
</ul>
<p><strong>Cache-Friendly Traversal:</strong> Optimize memory access patterns</p>
<ul>
<li>Layout connected nodes spatially close in memory</li>
<li>Prefetch neighbor data during graph traversal</li>
<li>Significant impact on large-scale deployments</li>
</ul>
<h3 id="ivf-inverted-file-index">IVF: Inverted File Index<a class="headerlink" href="#ivf-inverted-file-index" title="Permanent link">&para;</a></h3>
<p><a href="../glossary/#ivf-inverted-file-index">Inverted File Index (IVF)</a> represents a fundamentally different approach to vector search compared to graph-based methods like HNSW. By partitioning the vector space into distinct regions through clustering, IVF transforms the nearest neighbor problem from "search everywhere" to "search only where it matters." This approach excels particularly well for large-scale deployments where memory constraints and predictable performance characteristics are paramount.</p>
<h4 id="conceptual-foundation-and-mathematical-intuition">Conceptual Foundation and Mathematical Intuition<a class="headerlink" href="#conceptual-foundation-and-mathematical-intuition" title="Permanent link">&para;</a></h4>
<p><strong>The Divide-and-Conquer Philosophy</strong></p>
<p>IVF embodies a classic divide-and-conquer strategy adapted for high-dimensional spaces:</p>
<p><em>Geographic Analogy:</em> Consider finding the nearest coffee shop in a large city:</p>
<ul>
<li><strong>Naive approach:</strong> Check every coffee shop in the entire city</li>
<li><strong>IVF approach:</strong> Divide the city into neighborhoods, identify which neighborhoods you're likely to find coffee shops near your location, then search only those neighborhoods</li>
</ul>
<p><em>Library Science Analogy:</em></p>
<ul>
<li><strong>Traditional library:</strong> Books scattered randomly - must check every shelf</li>
<li><strong>Dewey Decimal System (IVF):</strong> Books organized by topic - go directly to relevant sections</li>
</ul>
<p><strong>Mathematical Foundation: The Locality Hypothesis</strong></p>
<p>IVF relies on the <strong>locality principle</strong> in high-dimensional spaces:</p>
<p><em>Formal Statement:</em> If vectors v1 and v2 are close in the original space, and if vector q is close to v1, then q is likely closer to vectors in the same cluster as v1 than to vectors in distant clusters.</p>
<p><em>Mathematical Expression:</em>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>For vectors v1, v2 in cluster Ci and query q:
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>P(NN(q) ∈ Ci | d(q, centroid_i) &lt; d(q, centroid_j) ∀j≠i) &gt; threshold
</code></pre></div></p>
<p>This principle holds particularly well in high-dimensional spaces due to the <strong>concentration of measure phenomenon</strong> - in high dimensions, most vectors concentrate in a thin shell around the centroid, making cluster boundaries more meaningful.</p>
<p><strong>Three-Phase IVF Architecture:</strong></p>
<p><em>Phase 1: Offline Clustering (Training)</em></p>
<ul>
<li>Analyze the entire vector dataset to identify natural groupings</li>
<li>Use k-means or more sophisticated clustering algorithms</li>
<li>Create centroids that represent cluster "centers of mass"</li>
<li>Build inverted lists mapping centroids to their member vectors</li>
</ul>
<p><em>Phase 2: Vector Assignment (Indexing)</em></p>
<ul>
<li>For each new vector, determine its nearest cluster centroid</li>
<li>Add the vector to that cluster's inverted list</li>
<li>Update cluster statistics for future optimization</li>
</ul>
<p><em>Phase 3: Query Processing (Search)</em></p>
<ul>
<li>Calculate distances from query to all cluster centroids</li>
<li>Select the k most promising clusters (nprobes parameter)</li>
<li>Search within selected clusters using exhaustive comparison</li>
<li>Merge results across clusters for final ranking</li>
</ul>
<p><strong>Why This Architecture Scales</strong></p>
<p><em>Complexity Reduction:</em> Instead of O(N) comparisons for brute force search, IVF achieves:</p>
<ul>
<li>O(√N) centroid comparisons (for optimal nlist ≈ √N)</li>
<li>O(N/nlist × nprobes) vector comparisons within selected clusters</li>
<li>Total: O(√N + (N×nprobes)/nlist)</li>
</ul>
<p><em>Memory Efficiency:</em> Cluster centroids (typically 1000-10000) fit easily in cache, while member vectors can be stored in compressed formats or on disk.</p>
<p><em>Parallelization:</em> Different clusters can be searched independently, enabling efficient distributed processing.</p>
<h4 id="advanced-ivf-techniques-and-optimizations">Advanced IVF Techniques and Optimizations<a class="headerlink" href="#advanced-ivf-techniques-and-optimizations" title="Permanent link">&para;</a></h4>
<p><em>Modern IVF implementations incorporate sophisticated optimizations that significantly improve both accuracy and performance beyond the basic algorithm.</em></p>
<p><strong>Multi-Probe LSH (Locality Sensitive Hashing):</strong></p>
<p>Instead of only searching the closest cluster centroids, examine multiple probe sequences that might contain query neighbors. This technique particularly helps when query vectors lie near cluster boundaries.</p>
<p><strong>Cluster Refinement:</strong></p>
<p>Periodically retrain cluster centroids using updated vector distributions, especially important for dynamic datasets where new vectors might shift optimal partitioning.</p>
<p><strong>Asymmetric vs Symmetric Distance Computation:</strong></p>
<ul>
<li><strong>Asymmetric Distance:</strong> More accurate, computes direct distance between query and clustered vector</li>
<li><strong>Symmetric Distance:</strong> Faster approximation using centroid as intermediate point</li>
<li><strong>Trade-off:</strong> Asymmetric provides better accuracy at higher computational cost</li>
</ul>
<h3 id="product-quantization">Product Quantization<a class="headerlink" href="#product-quantization" title="Permanent link">&para;</a></h3>
<p><a href="../glossary/#product-quantization-pq">Product Quantization (PQ)</a> represents one of the most mathematically elegant solutions to the vector compression problem. By exploiting the principle of dimensional independence in high-dimensional spaces, PQ achieves dramatic memory compression while preserving essential similarity relationships through learned subspace quantization.</p>
<h4 id="conceptual-understanding-and-mathematical-foundation">Conceptual Understanding and Mathematical Foundation<a class="headerlink" href="#conceptual-understanding-and-mathematical-foundation" title="Permanent link">&para;</a></h4>
<p><strong>The Dimensional Independence Hypothesis</strong></p>
<p>Product Quantization is based on a key insight about high-dimensional vector spaces: different dimensions often capture orthogonal or semi-orthogonal aspects of the underlying semantic space. This allows us to compress each subspace independently without catastrophic information loss.</p>
<p><strong>Information-Theoretic Perspective:</strong></p>
<p>Consider a D-dimensional vector space where each dimension requires 32 bits (float32). The total information content is 32D bits per vector. PQ recognizes that much of this precision is unnecessary for similarity preservation and that dimensions can be grouped and compressed independently.</p>
<p><strong>The Product Space Decomposition:</strong></p>
<p><em>Mathematical Formulation:</em>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>Original space: ℝᴰ
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>Product decomposition: ℝᴰ ≅ ℝᴰ/ᵐ × ℝᴰ/ᵐ × ... × ℝᴰ/ᵐ (m times)
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a>Where each subspace ℝᴰ/ᵐ is quantized independently
</code></pre></div></p>
<p><em>Key Insight:</em> If the original vector space has natural clustering structure, then subspaces will also exhibit clustering, making k-means quantization effective in each subspace.</p>
<p><strong>Advanced Analogies:</strong></p>
<p><em>Digital Image Compression:</em></p>
<ul>
<li><strong>JPEG approach:</strong> Transform to frequency domain, quantize coefficients</li>
<li><strong>PQ approach:</strong> Spatial decomposition into blocks, quantize each block independently</li>
<li><strong>Key difference:</strong> PQ learns optimal quantization codebooks from data rather than using predetermined schemes</li>
</ul>
<p><em>Dictionary Compression:</em></p>
<ul>
<li><strong>Traditional:</strong> Build one dictionary for entire document</li>
<li><strong>PQ approach:</strong> Build specialized dictionaries for different parts of speech/topics</li>
<li><strong>Advantage:</strong> Each dictionary captures local patterns more effectively</li>
</ul>
<p><strong>Why Dimensional Independence Works in High Dimensions:</strong></p>
<ol>
<li><strong>Curse of Dimensionality Benefits:</strong> In high-dimensional spaces, vectors become increasingly orthogonal, making dimensional correlations weaker</li>
<li><strong>Embedding Structure:</strong> Modern embedding models often encode different semantic aspects in distinct dimensional ranges</li>
<li><strong>Local Similarity Preservation:</strong> PQ preserves local neighborhood structure even with quantization errors</li>
</ol>
<h3 id="algorithm-selection-guide">Algorithm Selection Guide<a class="headerlink" href="#algorithm-selection-guide" title="Permanent link">&para;</a></h3>
<p>Choosing the optimal vector search algorithm requires understanding your specific requirements for accuracy, speed, memory usage, and dataset characteristics.</p>
<h4 id="comprehensive-decision-matrix">Comprehensive Decision Matrix<a class="headerlink" href="#comprehensive-decision-matrix" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Dataset Size</th>
<th>Memory Budget</th>
<th>Latency Requirement</th>
<th>Accuracy Need</th>
<th>Best Algorithm</th>
<th>Reasoning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>&lt; 100K</strong></td>
<td>Any</td>
<td>Any</td>
<td>100%</td>
<td><strong>Brute Force</strong></td>
<td>Small enough for exact search</td>
</tr>
<tr>
<td><strong>100K - 1M</strong></td>
<td>High (4GB+)</td>
<td>Ultra-low (&lt;1ms)</td>
<td>95%+</td>
<td><strong>HNSW</strong></td>
<td>Best speed-accuracy balance</td>
</tr>
<tr>
<td><strong>100K - 1M</strong></td>
<td>Medium (2-4GB)</td>
<td>Low (&lt;10ms)</td>
<td>90%+</td>
<td><strong>IVF</strong></td>
<td>Good efficiency, proven</td>
</tr>
<tr>
<td><strong>1M - 10M</strong></td>
<td>High (8GB+)</td>
<td>Low (&lt;5ms)</td>
<td>95%+</td>
<td><strong>HNSW</strong></td>
<td>Scales well, excellent recall</td>
</tr>
<tr>
<td><strong>1M - 10M</strong></td>
<td>Medium (3-8GB)</td>
<td>Medium (&lt;20ms)</td>
<td>90%+</td>
<td><strong>IVF</strong></td>
<td>Balanced approach</td>
</tr>
<tr>
<td><strong>10M+</strong></td>
<td>High (16GB+)</td>
<td>Medium (&lt;50ms)</td>
<td>90%+</td>
<td><strong>IVF</strong></td>
<td>Proven at massive scale</td>
</tr>
<tr>
<td><strong>10M+</strong></td>
<td>Low (&lt;2GB)</td>
<td>High (&lt;100ms)</td>
<td>80%+</td>
<td><strong>IVF + PQ</strong></td>
<td>Maximum compression</td>
</tr>
<tr>
<td><strong>Any</strong></td>
<td>Very Low (&lt;1GB)</td>
<td>Any</td>
<td>75%+</td>
<td><strong>PQ Only</strong></td>
<td>Extreme memory constraints</td>
</tr>
</tbody>
</table>
<h4 id="algorithm-specific-optimization-guidelines">Algorithm-Specific Optimization Guidelines<a class="headerlink" href="#algorithm-specific-optimization-guidelines" title="Permanent link">&para;</a></h4>
<p><strong>HNSW Parameter Optimization Guidelines:</strong></p>
<p><em>Base Parameter Selection by Latency Requirements:</em></p>
<ul>
<li><strong>Ultra-low latency (&lt;1ms):</strong> M=16, ef_construction=128</li>
<li><strong>Low latency (&lt;5ms):</strong> M=24, ef_construction=256</li>
<li><strong>Standard latency:</strong> M=32, ef_construction=512</li>
</ul>
<p><em>Memory-Constrained Adjustments:</em></p>
<ul>
<li>Reduce M by half if memory budget exceeded</li>
<li>Maintain minimum M=8 for connectivity</li>
</ul>
<p><em>Large Dataset Scaling:</em></p>
<ul>
<li>Limit ef_construction=256 for datasets &gt;5M vectors</li>
<li>Balance construction time vs quality</li>
</ul>
<p><em>Runtime ef_search Selection by Use Case:</em></p>
<ul>
<li><strong>Autocomplete:</strong> 20 (speed priority)</li>
<li><strong>Main search:</strong> 100 (balanced)</li>
<li><strong>Research:</strong> 300 (accuracy priority)</li>
<li><strong>Recommendations:</strong> 150 (moderate accuracy)</li>
<li><strong>Premium users:</strong> 2x base values (up to 500 max)</li>
</ul>
<p><strong>IVF Parameter Optimization Framework:</strong></p>
<p><em>Cluster Count (nlist) Calculation:</em></p>
<ul>
<li><strong>Base formula:</strong> √dataset_size × dimension_factor</li>
<li><strong>Dimension factor:</strong> max(1.0, dimensions/512)</li>
<li><strong>Constraints:</strong> min=32, max=dataset_size/39</li>
</ul>
<p><em>Search Width (nprobes) by Target Recall:</em></p>
<ul>
<li><strong>95%+ recall:</strong> 15% of clusters (min 100)</li>
<li><strong>90%+ recall:</strong> 10% of clusters (min 50)</li>
<li><strong>&lt;90% recall:</strong> 5% of clusters (min 20)</li>
</ul>
<p><em>Example Configurations:</em></p>
<ul>
<li>1M vectors, 384 dims, 95% recall → nlist=1,260, nprobes=189</li>
<li>10M vectors, 768 dims, 90% recall → nlist=4,800, nprobes=480</li>
</ul>
<p><strong>Product Quantization Parameter Selection:</strong></p>
<p><em>Subquantizer Count (m) by Memory Budget:</em></p>
<ul>
<li><strong>&lt;10% memory budget:</strong> m = dimensions/4 (aggressive compression)</li>
<li><strong>&lt;20% memory budget:</strong> m = dimensions/8 (balanced compression)</li>
<li><strong>&gt;20% memory budget:</strong> m = dimensions/16 (conservative compression)</li>
<li><strong>Constraint:</strong> m must divide dimensions evenly</li>
</ul>
<p><em>Centroids per Codebook (k) by Accuracy Requirements:</em></p>
<ul>
<li><strong>&gt;90% accuracy:</strong> k=256 (8-bit indices)</li>
<li><strong>&gt;85% accuracy:</strong> k=128 (7-bit indices)</li>
<li><strong>&lt;85% accuracy:</strong> k=64 (6-bit indices)</li>
</ul>
<p><em>Example Configurations:</em></p>
<ul>
<li>768 dims, 15% memory, 90% accuracy → m=96, k=256 (32:1 compression)</li>
<li>1536 dims, 8% memory, 85% accuracy → m=192, k=128 (85:1 compression)</li>
</ul>
<h4 id="hybrid-algorithm-strategies">Hybrid Algorithm Strategies<a class="headerlink" href="#hybrid-algorithm-strategies" title="Permanent link">&para;</a></h4>
<p><strong>Cascading Search Strategy:</strong></p>
<p>Use fast approximate algorithms to filter candidates, then refine with more accurate methods:</p>
<p><em>Two-Stage Process:</em></p>
<ol>
<li><strong>Stage 1:</strong> Fast filtering with PQ (retrieve k×10 candidates)</li>
<li><strong>Stage 2:</strong> Rerank with full precision using exact distance calculations</li>
</ol>
<p><em>Benefits:</em></p>
<ul>
<li>Combines speed of approximate search with accuracy of exact ranking</li>
<li>Reduces computational cost while maintaining high precision</li>
<li>Particularly effective for large-scale deployments</li>
</ul>
<p><strong>Dynamic Algorithm Selection:</strong></p>
<p>Choose algorithms based on query and dataset characteristics:</p>
<p><em>Selection Criteria:</em></p>
<ul>
<li><strong>High-magnitude queries:</strong> Use exact search (&lt;50K vectors) or HNSW (larger datasets)</li>
<li><strong>Sparse queries:</strong> Prefer IVF clustering approach</li>
<li><strong>Standard queries:</strong> HNSW for &lt;5M vectors, IVF for larger datasets</li>
</ul>
<p><em>Benefits:</em></p>
<ul>
<li>Optimizes performance for different query types</li>
<li>Adapts to dataset characteristics automatically</li>
<li>Balances accuracy and computational efficiency</li>
</ul>
<hr />
<h2 id="part-iii-opensearch-implementation">Part III: OpenSearch Implementation<a class="headerlink" href="#part-iii-opensearch-implementation" title="Permanent link">&para;</a></h2>
<h3 id="opensearch-vector-architecture">OpenSearch Vector Architecture<a class="headerlink" href="#opensearch-vector-architecture" title="Permanent link">&para;</a></h3>
<p>OpenSearch extends Apache Lucene's robust document storage and search capabilities with specialized vector search functionality, creating a unified platform for both traditional text search and modern vector-based semantic search.</p>
<h4 id="core-architecture-components">Core Architecture Components<a class="headerlink" href="#core-architecture-components" title="Permanent link">&para;</a></h4>
<p><strong>Integrated Storage Model:</strong></p>
<p>OpenSearch stores vectors alongside traditional document fields, enabling rich queries that combine text filters, metadata constraints, and vector similarity in a single operation.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>Document Structure:
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>{
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>  &quot;_id&quot;: &quot;doc_123&quot;,
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>  &quot;_source&quot;: {
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>    &quot;title&quot;: &quot;Machine Learning Fundamentals&quot;,
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>    &quot;content&quot;: &quot;Introduction to ML algorithms...&quot;,
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>    &quot;category&quot;: &quot;education&quot;,
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>    &quot;timestamp&quot;: &quot;2024-01-15T10:00:00Z&quot;,
<a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>    &quot;content_vector&quot;: [0.1, -0.2, 0.8, ...],  // 384-dimensional vector
<a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>    &quot;title_vector&quot;: [0.3, 0.1, -0.4, ...]     // Separate vector for title
<a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>  }
<a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>}
</code></pre></div>
<p><strong>Segment-Based Vector Storage:</strong></p>
<p>OpenSearch leverages Lucene's segment architecture for vector storage, providing several key benefits:</p>
<ol>
<li><strong>Immutable Segments:</strong> Once written, segments don't change, enabling efficient memory mapping and caching</li>
<li><strong>Parallel Processing:</strong> Multiple segments can be searched concurrently</li>
<li><strong>Incremental Updates:</strong> New data creates new segments rather than modifying existing ones</li>
<li><strong>Memory Management:</strong> Vectors stored in off-heap memory-mapped files</li>
</ol>
<p><strong>Vector Index Files per Segment:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>Segment Directory:
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>├── vectors.vec      # Raw vector data (memory-mapped)
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>├── vector_meta.vem  # Vector metadata and mappings
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>├── hnsw_graph.hng   # HNSW graph structure (if used)
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>├── ivf_clusters.ivc # IVF cluster assignments (if used)
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>└── documents.json   # Traditional Lucene document storage
</code></pre></div>
<h4 id="memory-management-strategy">Memory Management Strategy<a class="headerlink" href="#memory-management-strategy" title="Permanent link">&para;</a></h4>
<p><strong>Off-Heap Vector Storage:</strong></p>
<p>OpenSearch stores vector data off-heap to avoid garbage collection pressure and enable memory mapping:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="c1"># Memory allocation example for 1M vectors, 384 dimensions</span>
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="n">vector_storage</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>    <span class="s2">&quot;raw_vectors&quot;</span><span class="p">:</span> <span class="s2">&quot;1M × 384 × 4 bytes = 1.54GB (memory-mapped)&quot;</span><span class="p">,</span>
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>    <span class="s2">&quot;hnsw_graph&quot;</span><span class="p">:</span> <span class="s2">&quot;1M × 24 connections × 4 bytes = 96MB (direct memory)&quot;</span><span class="p">,</span>
<a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>    <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="s2">&quot;1M × 64 bytes = 64MB (heap)&quot;</span><span class="p">,</span>
<a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>    <span class="s2">&quot;total_memory&quot;</span><span class="p">:</span> <span class="s2">&quot;~6GB including system overhead&quot;</span>
<a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a><span class="p">}</span>
</code></pre></div>
<p><strong>Query Processing Memory:</strong></p>
<p>Temporary structures for query processing use on-heap memory:
- Query vector parsing and normalization
- Similarity score calculations
- Result ranking and aggregation</p>
<p><strong>Caching Strategy:</strong></p>
<ul>
<li><strong>Vector cache:</strong> Recently accessed vectors cached in direct memory</li>
<li><strong>Graph cache:</strong> Frequently traversed graph regions kept in memory</li>
<li><strong>Query cache:</strong> Common query patterns cached for repeated execution</li>
</ul>
<h4 id="engine-architecture">Engine Architecture<a class="headerlink" href="#engine-architecture" title="Permanent link">&para;</a></h4>
<p><strong>Lucene Integration:</strong></p>
<p>OpenSearch vector search builds on Lucene's KnnVectorField implementation while adding:</p>
<ul>
<li>Multiple algorithm support (HNSW, IVF)</li>
<li>Advanced parameter tuning</li>
<li>Production-ready optimizations</li>
</ul>
<p><strong>Query Execution Pipeline:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>1. Query Parsing → Parse knn/vector query syntax
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>2. Vector Validation → Verify dimensions and format
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>3. Algorithm Selection → Choose HNSW vs IVF based on index config
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>4. Segment Search → Execute vector search across all segments
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>5. Score Aggregation → Combine results from multiple segments
<a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>6. Filter Application → Apply any additional query filters
<a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a>7. Result Ranking → Final ranking and relevance scoring
</code></pre></div>
<h3 id="index-configuration-and-setup">Index Configuration and Setup<a class="headerlink" href="#index-configuration-and-setup" title="Permanent link">&para;</a></h3>
<p>Proper index configuration is crucial for optimal vector search performance. OpenSearch provides extensive configuration options for different algorithms and use cases.</p>
<h4 id="basic-vector-field-configuration">Basic Vector Field Configuration<a class="headerlink" href="#basic-vector-field-configuration" title="Permanent link">&para;</a></h4>
<p><strong>Simple Vector Field:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="p">{</span>
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="w">  </span><span class="nt">&quot;mappings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="w">    </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="w">      </span><span class="nt">&quot;content_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-19-6" name="__codelineno-19-6" href="#__codelineno-19-6"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">384</span><span class="p">,</span>
<a id="__codelineno-19-7" name="__codelineno-19-7" href="#__codelineno-19-7"></a><span class="w">        </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cosinesimil&quot;</span>
<a id="__codelineno-19-8" name="__codelineno-19-8" href="#__codelineno-19-8"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-19-9" name="__codelineno-19-9" href="#__codelineno-19-9"></a><span class="w">      </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">},</span>
<a id="__codelineno-19-10" name="__codelineno-19-10" href="#__codelineno-19-10"></a><span class="w">      </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">},</span>
<a id="__codelineno-19-11" name="__codelineno-19-11" href="#__codelineno-19-11"></a><span class="w">      </span><span class="nt">&quot;category&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="p">},</span>
<a id="__codelineno-19-12" name="__codelineno-19-12" href="#__codelineno-19-12"></a><span class="w">      </span><span class="nt">&quot;timestamp&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;date&quot;</span><span class="p">}</span>
<a id="__codelineno-19-13" name="__codelineno-19-13" href="#__codelineno-19-13"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-19-14" name="__codelineno-19-14" href="#__codelineno-19-14"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-19-15" name="__codelineno-19-15" href="#__codelineno-19-15"></a><span class="p">}</span>
</code></pre></div>
<p><strong>Space Type Options:</strong></p>
<ul>
<li><strong>"cosinesimil":</strong> Cosine similarity (recommended for text embeddings)</li>
<li><strong>"l2":</strong> Euclidean distance (good for normalized embeddings)</li>
<li><strong>"l1":</strong> Manhattan distance (robust for sparse vectors)</li>
<li><strong>"linf":</strong> Maximum distance (specialized use cases)</li>
</ul>
<h4 id="hnsw-configuration">HNSW Configuration<a class="headerlink" href="#hnsw-configuration" title="Permanent link">&para;</a></h4>
<p><strong>Production HNSW Setup:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="p">{</span>
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="w">  </span><span class="nt">&quot;settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="w">    </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a><span class="w">      </span><span class="nt">&quot;knn&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a><span class="w">      </span><span class="nt">&quot;number_of_shards&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a><span class="w">      </span><span class="nt">&quot;number_of_replicas&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a><span class="w">      </span><span class="nt">&quot;refresh_interval&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;30s&quot;</span>
<a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-20-9" name="__codelineno-20-9" href="#__codelineno-20-9"></a><span class="w">  </span><span class="p">},</span>
<a id="__codelineno-20-10" name="__codelineno-20-10" href="#__codelineno-20-10"></a><span class="w">  </span><span class="nt">&quot;mappings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-20-11" name="__codelineno-20-11" href="#__codelineno-20-11"></a><span class="w">    </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-20-12" name="__codelineno-20-12" href="#__codelineno-20-12"></a><span class="w">      </span><span class="nt">&quot;content_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-20-13" name="__codelineno-20-13" href="#__codelineno-20-13"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-20-14" name="__codelineno-20-14" href="#__codelineno-20-14"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">384</span><span class="p">,</span>
<a id="__codelineno-20-15" name="__codelineno-20-15" href="#__codelineno-20-15"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-20-16" name="__codelineno-20-16" href="#__codelineno-20-16"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;hnsw&quot;</span><span class="p">,</span>
<a id="__codelineno-20-17" name="__codelineno-20-17" href="#__codelineno-20-17"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cosinesimil&quot;</span><span class="p">,</span>
<a id="__codelineno-20-18" name="__codelineno-20-18" href="#__codelineno-20-18"></a><span class="w">          </span><span class="nt">&quot;engine&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;lucene&quot;</span><span class="p">,</span>
<a id="__codelineno-20-19" name="__codelineno-20-19" href="#__codelineno-20-19"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-20-20" name="__codelineno-20-20" href="#__codelineno-20-20"></a><span class="w">            </span><span class="nt">&quot;ef_construction&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="err">Higher</span><span class="w"> </span><span class="err">=</span><span class="w"> </span><span class="err">be</span><span class="kc">tter</span><span class="w"> </span><span class="err">quali</span><span class="kc">t</span><span class="err">y</span><span class="p">,</span><span class="w"> </span><span class="err">slower</span><span class="w"> </span><span class="err">build</span>
<a id="__codelineno-20-21" name="__codelineno-20-21" href="#__codelineno-20-21"></a><span class="w">            </span><span class="nt">&quot;m&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="w">                  </span><span class="err">#</span><span class="w"> </span><span class="err">Higher</span><span class="w"> </span><span class="err">=</span><span class="w"> </span><span class="err">be</span><span class="kc">tter</span><span class="w"> </span><span class="err">recall</span><span class="p">,</span><span class="w"> </span><span class="err">more</span><span class="w"> </span><span class="err">memory</span>
<a id="__codelineno-20-22" name="__codelineno-20-22" href="#__codelineno-20-22"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-20-23" name="__codelineno-20-23" href="#__codelineno-20-23"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-20-24" name="__codelineno-20-24" href="#__codelineno-20-24"></a><span class="w">      </span><span class="p">}</span>
<a id="__codelineno-20-25" name="__codelineno-20-25" href="#__codelineno-20-25"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-20-26" name="__codelineno-20-26" href="#__codelineno-20-26"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-20-27" name="__codelineno-20-27" href="#__codelineno-20-27"></a><span class="p">}</span>
</code></pre></div>
<p><strong>Parameter Selection Guidelines:</strong></p>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>ef_construction</th>
<th>M</th>
<th>Reasoning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Development/Testing</strong></td>
<td>128</td>
<td>16</td>
<td>Fast iteration, adequate quality</td>
</tr>
<tr>
<td><strong>Production (Balanced)</strong></td>
<td>256</td>
<td>24</td>
<td>Good performance, manageable resources</td>
</tr>
<tr>
<td><strong>High Accuracy</strong></td>
<td>512</td>
<td>32</td>
<td>Maximum quality, higher resource usage</td>
</tr>
<tr>
<td><strong>Memory Constrained</strong></td>
<td>128</td>
<td>12</td>
<td>Reduced memory footprint</td>
</tr>
<tr>
<td><strong>Large Scale (10M+)</strong></td>
<td>256</td>
<td>24</td>
<td>Balanced for large datasets</td>
</tr>
</tbody>
</table>
<h4 id="ivf-configuration">IVF Configuration<a class="headerlink" href="#ivf-configuration" title="Permanent link">&para;</a></h4>
<p><strong>IVF Index Setup:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="p">{</span>
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="w">  </span><span class="nt">&quot;mappings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="w">    </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a><span class="w">      </span><span class="nt">&quot;content_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">768</span><span class="p">,</span>
<a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-21-8" name="__codelineno-21-8" href="#__codelineno-21-8"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ivf&quot;</span><span class="p">,</span>
<a id="__codelineno-21-9" name="__codelineno-21-9" href="#__codelineno-21-9"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;l2&quot;</span><span class="p">,</span>
<a id="__codelineno-21-10" name="__codelineno-21-10" href="#__codelineno-21-10"></a><span class="w">          </span><span class="nt">&quot;engine&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;lucene&quot;</span><span class="p">,</span>
<a id="__codelineno-21-11" name="__codelineno-21-11" href="#__codelineno-21-11"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-21-12" name="__codelineno-21-12" href="#__codelineno-21-12"></a><span class="w">            </span><span class="nt">&quot;nlist&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span><span class="w">     </span><span class="err">#</span><span class="w"> </span><span class="err">Number</span><span class="w"> </span><span class="err">o</span><span class="kc">f</span><span class="w"> </span><span class="err">clus</span><span class="kc">ters</span>
<a id="__codelineno-21-13" name="__codelineno-21-13" href="#__codelineno-21-13"></a><span class="w">            </span><span class="nt">&quot;nprobes&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">64</span><span class="w">      </span><span class="err">#</span><span class="w"> </span><span class="err">De</span><span class="kc">fault</span><span class="w"> </span><span class="err">search</span><span class="w"> </span><span class="err">wid</span><span class="kc">t</span><span class="err">h</span>
<a id="__codelineno-21-14" name="__codelineno-21-14" href="#__codelineno-21-14"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-21-15" name="__codelineno-21-15" href="#__codelineno-21-15"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-21-16" name="__codelineno-21-16" href="#__codelineno-21-16"></a><span class="w">      </span><span class="p">}</span>
<a id="__codelineno-21-17" name="__codelineno-21-17" href="#__codelineno-21-17"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-21-18" name="__codelineno-21-18" href="#__codelineno-21-18"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-21-19" name="__codelineno-21-19" href="#__codelineno-21-19"></a><span class="p">}</span>
</code></pre></div>
<p><strong>IVF Parameter Calculation Framework:</strong></p>
<p><em>Cluster Count Formula:</em></p>
<ul>
<li>Base: √expected_vector_count</li>
<li>Adjusted: base × max(1.0, dimensions/512)</li>
<li>Constrained: max(32, calculated_value)</li>
</ul>
<p><em>Search Width:</em></p>
<ul>
<li>Conservative: 10% of cluster count (minimum 8)</li>
</ul>
<p><em>Memory Estimation:</em></p>
<ul>
<li>Formula: vector_count × dimensions × 4 bytes</li>
</ul>
<p><em>Example Results:</em></p>
<ul>
<li>500K vectors, 384 dims → nlist=707, nprobes=71, ~0.7GB</li>
<li>5M vectors, 768 dims → nlist=3,464, nprobes=346, ~14.4GB</li>
</ul>
<h4 id="multi-vector-field-configuration">Multi-Vector Field Configuration<a class="headerlink" href="#multi-vector-field-configuration" title="Permanent link">&para;</a></h4>
<p><strong>Multiple Vector Fields for Different Purposes:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="p">{</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="w">  </span><span class="nt">&quot;mappings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="w">    </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a><span class="w">      </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">},</span>
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a><span class="w">      </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">},</span>
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a><span class="w">      </span><span class="nt">&quot;category&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="p">},</span>
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a>
<a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a><span class="w">      </span><span class="nt">&quot;title_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">384</span><span class="p">,</span>
<a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;hnsw&quot;</span><span class="p">,</span>
<a id="__codelineno-22-13" name="__codelineno-22-13" href="#__codelineno-22-13"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cosinesimil&quot;</span><span class="p">,</span>
<a id="__codelineno-22-14" name="__codelineno-22-14" href="#__codelineno-22-14"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;ef_construction&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;m&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">24</span><span class="p">}</span>
<a id="__codelineno-22-15" name="__codelineno-22-15" href="#__codelineno-22-15"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-22-16" name="__codelineno-22-16" href="#__codelineno-22-16"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-22-17" name="__codelineno-22-17" href="#__codelineno-22-17"></a>
<a id="__codelineno-22-18" name="__codelineno-22-18" href="#__codelineno-22-18"></a><span class="w">      </span><span class="nt">&quot;content_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-19" name="__codelineno-22-19" href="#__codelineno-22-19"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-22-20" name="__codelineno-22-20" href="#__codelineno-22-20"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">768</span><span class="p">,</span>
<a id="__codelineno-22-21" name="__codelineno-22-21" href="#__codelineno-22-21"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-22" name="__codelineno-22-22" href="#__codelineno-22-22"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;hnsw&quot;</span><span class="p">,</span>
<a id="__codelineno-22-23" name="__codelineno-22-23" href="#__codelineno-22-23"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cosinesimil&quot;</span><span class="p">,</span>
<a id="__codelineno-22-24" name="__codelineno-22-24" href="#__codelineno-22-24"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;ef_construction&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;m&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">}</span>
<a id="__codelineno-22-25" name="__codelineno-22-25" href="#__codelineno-22-25"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-22-26" name="__codelineno-22-26" href="#__codelineno-22-26"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-22-27" name="__codelineno-22-27" href="#__codelineno-22-27"></a>
<a id="__codelineno-22-28" name="__codelineno-22-28" href="#__codelineno-22-28"></a><span class="w">      </span><span class="nt">&quot;image_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-29" name="__codelineno-22-29" href="#__codelineno-22-29"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-22-30" name="__codelineno-22-30" href="#__codelineno-22-30"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span>
<a id="__codelineno-22-31" name="__codelineno-22-31" href="#__codelineno-22-31"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-32" name="__codelineno-22-32" href="#__codelineno-22-32"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ivf&quot;</span><span class="p">,</span>
<a id="__codelineno-22-33" name="__codelineno-22-33" href="#__codelineno-22-33"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;l2&quot;</span><span class="p">,</span>
<a id="__codelineno-22-34" name="__codelineno-22-34" href="#__codelineno-22-34"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;nlist&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;nprobes&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">}</span>
<a id="__codelineno-22-35" name="__codelineno-22-35" href="#__codelineno-22-35"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-22-36" name="__codelineno-22-36" href="#__codelineno-22-36"></a><span class="w">      </span><span class="p">}</span>
<a id="__codelineno-22-37" name="__codelineno-22-37" href="#__codelineno-22-37"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-22-38" name="__codelineno-22-38" href="#__codelineno-22-38"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-22-39" name="__codelineno-22-39" href="#__codelineno-22-39"></a><span class="p">}</span>
</code></pre></div>
<h3 id="reranking-in-opensearch">Reranking in OpenSearch<a class="headerlink" href="#reranking-in-opensearch" title="Permanent link">&para;</a></h3>
<p>OpenSearch provides several built-in mechanisms for implementing reranking, from simple rescoring queries to integration with external machine learning models. Understanding these capabilities enables you to improve search relevance significantly.</p>
<h4 id="native-rescoring-with-opensearch">Native Rescoring with OpenSearch<a class="headerlink" href="#native-rescoring-with-opensearch" title="Permanent link">&para;</a></h4>
<p><strong>Basic Rescore Query Structure:</strong></p>
<p>OpenSearch's <code>rescore</code> query allows you to apply a secondary query to refine the top results from your initial search:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="p">{</span>
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="w">  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="w">    </span><span class="nt">&quot;bool&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a><span class="w">      </span><span class="nt">&quot;must&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a><span class="w">          </span><span class="nt">&quot;multi_match&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a><span class="w">            </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;wireless headphones&quot;</span><span class="p">,</span>
<a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a><span class="w">            </span><span class="nt">&quot;fields&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;title^2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;description&quot;</span><span class="p">]</span>
<a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a><span class="w">      </span><span class="p">]</span>
<a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a><span class="w">  </span><span class="p">},</span>
<a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a><span class="w">  </span><span class="nt">&quot;rescore&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-15" name="__codelineno-23-15" href="#__codelineno-23-15"></a><span class="w">    </span><span class="nt">&quot;window_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">50</span><span class="p">,</span>
<a id="__codelineno-23-16" name="__codelineno-23-16" href="#__codelineno-23-16"></a><span class="w">    </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-17" name="__codelineno-23-17" href="#__codelineno-23-17"></a><span class="w">      </span><span class="nt">&quot;rescore_query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-18" name="__codelineno-23-18" href="#__codelineno-23-18"></a><span class="w">        </span><span class="nt">&quot;function_score&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-19" name="__codelineno-23-19" href="#__codelineno-23-19"></a><span class="w">          </span><span class="nt">&quot;functions&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-23-20" name="__codelineno-23-20" href="#__codelineno-23-20"></a><span class="w">            </span><span class="p">{</span>
<a id="__codelineno-23-21" name="__codelineno-23-21" href="#__codelineno-23-21"></a><span class="w">              </span><span class="nt">&quot;field_value_factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-22" name="__codelineno-23-22" href="#__codelineno-23-22"></a><span class="w">                </span><span class="nt">&quot;field&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;rating&quot;</span><span class="p">,</span>
<a id="__codelineno-23-23" name="__codelineno-23-23" href="#__codelineno-23-23"></a><span class="w">                </span><span class="nt">&quot;factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.2</span><span class="p">,</span>
<a id="__codelineno-23-24" name="__codelineno-23-24" href="#__codelineno-23-24"></a><span class="w">                </span><span class="nt">&quot;modifier&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;log1p&quot;</span>
<a id="__codelineno-23-25" name="__codelineno-23-25" href="#__codelineno-23-25"></a><span class="w">              </span><span class="p">}</span>
<a id="__codelineno-23-26" name="__codelineno-23-26" href="#__codelineno-23-26"></a><span class="w">            </span><span class="p">},</span>
<a id="__codelineno-23-27" name="__codelineno-23-27" href="#__codelineno-23-27"></a><span class="w">            </span><span class="p">{</span>
<a id="__codelineno-23-28" name="__codelineno-23-28" href="#__codelineno-23-28"></a><span class="w">              </span><span class="nt">&quot;field_value_factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-29" name="__codelineno-23-29" href="#__codelineno-23-29"></a><span class="w">                </span><span class="nt">&quot;field&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;review_count&quot;</span><span class="p">,</span>
<a id="__codelineno-23-30" name="__codelineno-23-30" href="#__codelineno-23-30"></a><span class="w">                </span><span class="nt">&quot;factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-23-31" name="__codelineno-23-31" href="#__codelineno-23-31"></a><span class="w">                </span><span class="nt">&quot;modifier&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;sqrt&quot;</span>
<a id="__codelineno-23-32" name="__codelineno-23-32" href="#__codelineno-23-32"></a><span class="w">              </span><span class="p">}</span>
<a id="__codelineno-23-33" name="__codelineno-23-33" href="#__codelineno-23-33"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-23-34" name="__codelineno-23-34" href="#__codelineno-23-34"></a><span class="w">          </span><span class="p">]</span>
<a id="__codelineno-23-35" name="__codelineno-23-35" href="#__codelineno-23-35"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-23-36" name="__codelineno-23-36" href="#__codelineno-23-36"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-23-37" name="__codelineno-23-37" href="#__codelineno-23-37"></a><span class="w">      </span><span class="nt">&quot;query_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.7</span><span class="p">,</span>
<a id="__codelineno-23-38" name="__codelineno-23-38" href="#__codelineno-23-38"></a><span class="w">      </span><span class="nt">&quot;rescore_query_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.3</span>
<a id="__codelineno-23-39" name="__codelineno-23-39" href="#__codelineno-23-39"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-23-40" name="__codelineno-23-40" href="#__codelineno-23-40"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-23-41" name="__codelineno-23-41" href="#__codelineno-23-41"></a><span class="p">}</span>
</code></pre></div>
<p><strong>Key Parameters:</strong></p>
<ul>
<li><strong>window_size:</strong> Number of top documents to rescore (typically 50-200)</li>
<li><strong>query_weight:</strong> Weight given to original query score (0.0-1.0)</li>
<li><strong>rescore_query_weight:</strong> Weight given to rescore query score (0.0-1.0)</li>
</ul>
<h4 id="advanced-function-scoring">Advanced Function Scoring<a class="headerlink" href="#advanced-function-scoring" title="Permanent link">&para;</a></h4>
<p><strong>Multi-Signal Reranking:</strong></p>
<p>Combine multiple relevance signals for sophisticated ranking:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="p">{</span>
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="w">  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="w">    </span><span class="nt">&quot;function_score&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="w">      </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="w">        </span><span class="nt">&quot;bool&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a><span class="w">          </span><span class="nt">&quot;should&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="w">            </span><span class="p">{</span>
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a><span class="w">              </span><span class="nt">&quot;match&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="w">                </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a><span class="w">                  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;machine learning&quot;</span><span class="p">,</span>
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a><span class="w">                  </span><span class="nt">&quot;boost&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2.0</span>
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a><span class="w">                </span><span class="p">}</span>
<a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a><span class="w">              </span><span class="p">}</span>
<a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a><span class="w">            </span><span class="p">},</span>
<a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a><span class="w">            </span><span class="p">{</span>
<a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a><span class="w">              </span><span class="nt">&quot;knn&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a><span class="w">                </span><span class="nt">&quot;content_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a><span class="w">                  </span><span class="nt">&quot;vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.2</span><span class="p">,</span><span class="w"> </span><span class="mf">0.8</span><span class="p">],</span>
<a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a><span class="w">                  </span><span class="nt">&quot;k&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">50</span>
<a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a><span class="w">                </span><span class="p">}</span>
<a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a><span class="w">              </span><span class="p">}</span>
<a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a><span class="w">          </span><span class="p">]</span>
<a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-24-25" name="__codelineno-24-25" href="#__codelineno-24-25"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-24-26" name="__codelineno-24-26" href="#__codelineno-24-26"></a><span class="w">      </span><span class="nt">&quot;functions&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-24-27" name="__codelineno-24-27" href="#__codelineno-24-27"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-24-28" name="__codelineno-24-28" href="#__codelineno-24-28"></a><span class="w">          </span><span class="nt">&quot;field_value_factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-29" name="__codelineno-24-29" href="#__codelineno-24-29"></a><span class="w">            </span><span class="nt">&quot;field&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;popularity_score&quot;</span><span class="p">,</span>
<a id="__codelineno-24-30" name="__codelineno-24-30" href="#__codelineno-24-30"></a><span class="w">            </span><span class="nt">&quot;factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.5</span><span class="p">,</span>
<a id="__codelineno-24-31" name="__codelineno-24-31" href="#__codelineno-24-31"></a><span class="w">            </span><span class="nt">&quot;modifier&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;sqrt&quot;</span><span class="p">,</span>
<a id="__codelineno-24-32" name="__codelineno-24-32" href="#__codelineno-24-32"></a><span class="w">            </span><span class="nt">&quot;missing&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span>
<a id="__codelineno-24-33" name="__codelineno-24-33" href="#__codelineno-24-33"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-24-34" name="__codelineno-24-34" href="#__codelineno-24-34"></a><span class="w">        </span><span class="p">},</span>
<a id="__codelineno-24-35" name="__codelineno-24-35" href="#__codelineno-24-35"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-24-36" name="__codelineno-24-36" href="#__codelineno-24-36"></a><span class="w">          </span><span class="nt">&quot;gauss&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-37" name="__codelineno-24-37" href="#__codelineno-24-37"></a><span class="w">            </span><span class="nt">&quot;publish_date&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-38" name="__codelineno-24-38" href="#__codelineno-24-38"></a><span class="w">              </span><span class="nt">&quot;origin&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;now&quot;</span><span class="p">,</span>
<a id="__codelineno-24-39" name="__codelineno-24-39" href="#__codelineno-24-39"></a><span class="w">              </span><span class="nt">&quot;scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;30d&quot;</span><span class="p">,</span>
<a id="__codelineno-24-40" name="__codelineno-24-40" href="#__codelineno-24-40"></a><span class="w">              </span><span class="nt">&quot;decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span>
<a id="__codelineno-24-41" name="__codelineno-24-41" href="#__codelineno-24-41"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-24-42" name="__codelineno-24-42" href="#__codelineno-24-42"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-24-43" name="__codelineno-24-43" href="#__codelineno-24-43"></a><span class="w">        </span><span class="p">},</span>
<a id="__codelineno-24-44" name="__codelineno-24-44" href="#__codelineno-24-44"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-24-45" name="__codelineno-24-45" href="#__codelineno-24-45"></a><span class="w">          </span><span class="nt">&quot;script_score&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-46" name="__codelineno-24-46" href="#__codelineno-24-46"></a><span class="w">            </span><span class="nt">&quot;script&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-47" name="__codelineno-24-47" href="#__codelineno-24-47"></a><span class="w">              </span><span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Math.log(doc[&#39;view_count&#39;].value + 1) * params.factor&quot;</span><span class="p">,</span>
<a id="__codelineno-24-48" name="__codelineno-24-48" href="#__codelineno-24-48"></a><span class="w">              </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-24-49" name="__codelineno-24-49" href="#__codelineno-24-49"></a><span class="w">                </span><span class="nt">&quot;factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.2</span>
<a id="__codelineno-24-50" name="__codelineno-24-50" href="#__codelineno-24-50"></a><span class="w">              </span><span class="p">}</span>
<a id="__codelineno-24-51" name="__codelineno-24-51" href="#__codelineno-24-51"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-24-52" name="__codelineno-24-52" href="#__codelineno-24-52"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-24-53" name="__codelineno-24-53" href="#__codelineno-24-53"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-24-54" name="__codelineno-24-54" href="#__codelineno-24-54"></a><span class="w">      </span><span class="p">],</span>
<a id="__codelineno-24-55" name="__codelineno-24-55" href="#__codelineno-24-55"></a><span class="w">      </span><span class="nt">&quot;score_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
<a id="__codelineno-24-56" name="__codelineno-24-56" href="#__codelineno-24-56"></a><span class="w">      </span><span class="nt">&quot;boost_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;multiply&quot;</span>
<a id="__codelineno-24-57" name="__codelineno-24-57" href="#__codelineno-24-57"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-24-58" name="__codelineno-24-58" href="#__codelineno-24-58"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-24-59" name="__codelineno-24-59" href="#__codelineno-24-59"></a><span class="p">}</span>
</code></pre></div>
<p><strong>Function Types:</strong></p>
<ul>
<li><strong>field_value_factor:</strong> Use document field values as scoring factors</li>
<li><strong>gauss/linear/exp:</strong> Distance-based decay functions for date, location, numerical ranges</li>
<li><strong>script_score:</strong> Custom scoring logic using Painless scripts</li>
<li><strong>random_score:</strong> Add controlled randomization to prevent result staleness</li>
</ul>
<h4 id="hybrid-search-with-reranking">Hybrid Search with Reranking<a class="headerlink" href="#hybrid-search-with-reranking" title="Permanent link">&para;</a></h4>
<p><strong>Combining Text and Vector Search with Reranking:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="p">{</span>
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="w">  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="w">    </span><span class="nt">&quot;bool&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a><span class="w">      </span><span class="nt">&quot;should&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a><span class="w">          </span><span class="nt">&quot;multi_match&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a><span class="w">            </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;sustainable energy solutions&quot;</span><span class="p">,</span>
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a><span class="w">            </span><span class="nt">&quot;fields&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;title^3&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;content&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;tags^2&quot;</span><span class="p">],</span>
<a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a><span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;best_fields&quot;</span>
<a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a><span class="w">        </span><span class="p">},</span>
<a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a><span class="w">          </span><span class="nt">&quot;knn&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a><span class="w">            </span><span class="nt">&quot;content_vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a><span class="w">              </span><span class="nt">&quot;vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.1</span><span class="p">,</span><span class="w"> </span><span class="mf">0.9</span><span class="p">],</span>
<a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a><span class="w">              </span><span class="nt">&quot;k&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span>
<a id="__codelineno-25-17" name="__codelineno-25-17" href="#__codelineno-25-17"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-25-18" name="__codelineno-25-18" href="#__codelineno-25-18"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-25-19" name="__codelineno-25-19" href="#__codelineno-25-19"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-25-20" name="__codelineno-25-20" href="#__codelineno-25-20"></a><span class="w">      </span><span class="p">]</span>
<a id="__codelineno-25-21" name="__codelineno-25-21" href="#__codelineno-25-21"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-25-22" name="__codelineno-25-22" href="#__codelineno-25-22"></a><span class="w">  </span><span class="p">},</span>
<a id="__codelineno-25-23" name="__codelineno-25-23" href="#__codelineno-25-23"></a><span class="w">  </span><span class="nt">&quot;rescore&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-24" name="__codelineno-25-24" href="#__codelineno-25-24"></a><span class="w">    </span><span class="nt">&quot;window_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-25-25" name="__codelineno-25-25" href="#__codelineno-25-25"></a><span class="w">    </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-26" name="__codelineno-25-26" href="#__codelineno-25-26"></a><span class="w">      </span><span class="nt">&quot;rescore_query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-27" name="__codelineno-25-27" href="#__codelineno-25-27"></a><span class="w">        </span><span class="nt">&quot;function_score&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-28" name="__codelineno-25-28" href="#__codelineno-25-28"></a><span class="w">          </span><span class="nt">&quot;functions&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-25-29" name="__codelineno-25-29" href="#__codelineno-25-29"></a><span class="w">            </span><span class="p">{</span>
<a id="__codelineno-25-30" name="__codelineno-25-30" href="#__codelineno-25-30"></a><span class="w">              </span><span class="nt">&quot;field_value_factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-31" name="__codelineno-25-31" href="#__codelineno-25-31"></a><span class="w">                </span><span class="nt">&quot;field&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;authority_score&quot;</span><span class="p">,</span>
<a id="__codelineno-25-32" name="__codelineno-25-32" href="#__codelineno-25-32"></a><span class="w">                </span><span class="nt">&quot;factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2.0</span><span class="p">,</span>
<a id="__codelineno-25-33" name="__codelineno-25-33" href="#__codelineno-25-33"></a><span class="w">                </span><span class="nt">&quot;modifier&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;log1p&quot;</span>
<a id="__codelineno-25-34" name="__codelineno-25-34" href="#__codelineno-25-34"></a><span class="w">              </span><span class="p">}</span>
<a id="__codelineno-25-35" name="__codelineno-25-35" href="#__codelineno-25-35"></a><span class="w">            </span><span class="p">},</span>
<a id="__codelineno-25-36" name="__codelineno-25-36" href="#__codelineno-25-36"></a><span class="w">            </span><span class="p">{</span>
<a id="__codelineno-25-37" name="__codelineno-25-37" href="#__codelineno-25-37"></a><span class="w">              </span><span class="nt">&quot;field_value_factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-25-38" name="__codelineno-25-38" href="#__codelineno-25-38"></a><span class="w">                </span><span class="nt">&quot;field&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;recency_boost&quot;</span><span class="p">,</span>
<a id="__codelineno-25-39" name="__codelineno-25-39" href="#__codelineno-25-39"></a><span class="w">                </span><span class="nt">&quot;factor&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-25-40" name="__codelineno-25-40" href="#__codelineno-25-40"></a><span class="w">                </span><span class="nt">&quot;modifier&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;none&quot;</span>
<a id="__codelineno-25-41" name="__codelineno-25-41" href="#__codelineno-25-41"></a><span class="w">              </span><span class="p">}</span>
<a id="__codelineno-25-42" name="__codelineno-25-42" href="#__codelineno-25-42"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-25-43" name="__codelineno-25-43" href="#__codelineno-25-43"></a><span class="w">          </span><span class="p">],</span>
<a id="__codelineno-25-44" name="__codelineno-25-44" href="#__codelineno-25-44"></a><span class="w">          </span><span class="nt">&quot;score_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;multiply&quot;</span>
<a id="__codelineno-25-45" name="__codelineno-25-45" href="#__codelineno-25-45"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-25-46" name="__codelineno-25-46" href="#__codelineno-25-46"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-25-47" name="__codelineno-25-47" href="#__codelineno-25-47"></a><span class="w">      </span><span class="nt">&quot;query_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.8</span><span class="p">,</span>
<a id="__codelineno-25-48" name="__codelineno-25-48" href="#__codelineno-25-48"></a><span class="w">      </span><span class="nt">&quot;rescore_query_weight&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.2</span>
<a id="__codelineno-25-49" name="__codelineno-25-49" href="#__codelineno-25-49"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-25-50" name="__codelineno-25-50" href="#__codelineno-25-50"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-25-51" name="__codelineno-25-51" href="#__codelineno-25-51"></a><span class="p">}</span>
</code></pre></div>
<h4 id="external-neural-reranking-integration">External Neural Reranking Integration<a class="headerlink" href="#external-neural-reranking-integration" title="Permanent link">&para;</a></h4>
<p><strong>Pipeline Architecture for Neural Reranking:</strong></p>
<p>Modern OpenSearch deployments often integrate with external reranking services for advanced neural reranking:</p>
<p><strong>Step 1: Initial Retrieval</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="c1"># OpenSearch returns top 100-200 candidates</span>
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span><span class="s2">&quot;localhost:9200/documents/_search&quot;</span><span class="w"> </span><span class="se">\</span>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a><span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a><span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a><span class="s1">    &quot;size&quot;: 200,</span>
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a><span class="s1">    &quot;query&quot;: {</span>
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a><span class="s1">      &quot;bool&quot;: {</span>
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a><span class="s1">        &quot;should&quot;: [</span>
<a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a><span class="s1">          {&quot;match&quot;: {&quot;content&quot;: &quot;machine learning&quot;}},</span>
<a id="__codelineno-26-10" name="__codelineno-26-10" href="#__codelineno-26-10"></a><span class="s1">          {&quot;knn&quot;: {&quot;content_vector&quot;: {&quot;vector&quot;: [...], &quot;k&quot;: 100}}}</span>
<a id="__codelineno-26-11" name="__codelineno-26-11" href="#__codelineno-26-11"></a><span class="s1">        ]</span>
<a id="__codelineno-26-12" name="__codelineno-26-12" href="#__codelineno-26-12"></a><span class="s1">      }</span>
<a id="__codelineno-26-13" name="__codelineno-26-13" href="#__codelineno-26-13"></a><span class="s1">    }</span>
<a id="__codelineno-26-14" name="__codelineno-26-14" href="#__codelineno-26-14"></a><span class="s1">  }&#39;</span>
</code></pre></div></p>
<p><strong>Step 2: Feature Extraction</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="c1"># Extract additional signals for reranking</span>
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a><span class="n">features</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>    <span class="s2">&quot;query_document_similarity&quot;</span><span class="p">:</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">query_vector</span><span class="p">,</span> <span class="n">doc_vector</span><span class="p">),</span>
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>    <span class="s2">&quot;user_click_score&quot;</span><span class="p">:</span> <span class="n">user_interaction_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>    <span class="s2">&quot;content_quality&quot;</span><span class="p">:</span> <span class="n">quality_metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>    <span class="s2">&quot;temporal_relevance&quot;</span><span class="p">:</span> <span class="n">calculate_temporal_decay</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">publish_date</span><span class="p">)</span>
<a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a><span class="p">}</span>
</code></pre></div></p>
<p><strong>Step 3: Neural Reranking</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="c1"># Apply transformer-based reranking model</span>
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a><span class="n">reranked_scores</span> <span class="o">=</span> <span class="n">neural_reranker</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
<a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>    <span class="n">query_text</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
<a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>    <span class="n">document_texts</span><span class="o">=</span><span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">],</span>
<a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a>    <span class="n">features</span><span class="o">=</span><span class="n">features</span>
<a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a><span class="p">)</span>
</code></pre></div></p>
<p><strong>Step 4: Result Integration</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="c1"># Return reranked results to user</span>
<a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a><span class="n">final_results</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
<a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>    <span class="nb">zip</span><span class="p">(</span><span class="n">candidates</span><span class="p">,</span> <span class="n">reranked_scores</span><span class="p">),</span>
<a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a>    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
<a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a><span class="p">)</span>
</code></pre></div></p>
<h4 id="performance-optimization">Performance Optimization<a class="headerlink" href="#performance-optimization" title="Permanent link">&para;</a></h4>
<p><strong>Reranking Performance Tuning:</strong></p>
<ul>
<li><strong>Window Size Optimization:</strong> Start with 50, increase to 100-200 for better quality</li>
<li><strong>Weight Balancing:</strong> Use 70-80% original query weight, 20-30% rescore weight</li>
<li><strong>Caching Strategies:</strong> Cache rescore results for popular queries</li>
<li><strong>Async Processing:</strong> Implement asynchronous reranking for real-time applications</li>
</ul>
<p><strong>Resource Management:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="p">{</span>
<a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a><span class="w">  </span><span class="nt">&quot;search&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="w">    </span><span class="nt">&quot;max_buckets&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">10000</span><span class="p">,</span>
<a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="w">    </span><span class="nt">&quot;max_rescore_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">10000</span>
<a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a><span class="w">  </span><span class="p">},</span>
<a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a><span class="w">  </span><span class="nt">&quot;indices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a><span class="w">    </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a><span class="w">      </span><span class="nt">&quot;bool&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a><span class="w">        </span><span class="nt">&quot;max_clause_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2048</span>
<a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a><span class="w">      </span><span class="p">}</span>
<a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-30-13" name="__codelineno-30-13" href="#__codelineno-30-13"></a><span class="p">}</span>
</code></pre></div>
<hr />
<h2 id="part-iv-advanced-applications">Part IV: Advanced Applications<a class="headerlink" href="#part-iv-advanced-applications" title="Permanent link">&para;</a></h2>
<h3 id="multi-modal-search">Multi-modal Search<a class="headerlink" href="#multi-modal-search" title="Permanent link">&para;</a></h3>
<p>Multi-modal search enables searching across different content types (text, images, audio) using unified vector representations, opening new possibilities for content discovery and retrieval.</p>
<h4 id="understanding-multi-modal-vector-search">Understanding Multi-Modal Vector Search<a class="headerlink" href="#understanding-multi-modal-vector-search" title="Permanent link">&para;</a></h4>
<p><strong>Cross-Modal Understanding:</strong></p>
<p>Multi-modal search transcends traditional single-content-type search by enabling queries across heterogeneous data types. This capability allows users to search for images using text descriptions, find videos using audio queries, or discover text documents using image inputs.</p>
<p><strong>Key Advantages:</strong></p>
<ul>
<li><strong>Natural Query Expression:</strong> Users can express intent using the most convenient modality</li>
<li><strong>Content Discovery:</strong> Find related content across different media types</li>
<li><strong>Accessibility:</strong> Enable alternative access methods for users with different needs</li>
<li><strong>Rich Results:</strong> Provide diverse result sets combining multiple content types</li>
</ul>
<p><strong>Technical Foundation:</strong></p>
<p>Multi-modal search relies on embedding models trained on paired data across modalities, such as CLIP (Contrastive Language-Image Pre-training) for text-image pairs, or specialized audio-text models. These models learn shared representations where semantically similar content clusters together regardless of its original format.</p>
<p><strong>Common Use Cases:</strong></p>
<ul>
<li><strong>E-commerce:</strong> Search for products using text descriptions to find matching images</li>
<li><strong>Media Libraries:</strong> Find videos or images using natural language descriptions</li>
<li><strong>Educational Content:</strong> Discover learning materials across text, video, and image formats</li>
<li><strong>Research Databases:</strong> Cross-reference findings across papers, diagrams, and datasets </li>
</ul>
<h4 id="cross-modal-search-architecture">Cross-Modal Search Architecture<a class="headerlink" href="#cross-modal-search-architecture" title="Permanent link">&para;</a></h4>
<p><strong>Unified Embedding Space:</strong></p>
<p>Multi-modal search relies on embedding models that map different content types into a shared semantic space where similar concepts cluster together regardless of modality.</p>
<p><strong>Shared Vector Space Design:</strong></p>
<p>The core innovation of multi-modal search lies in creating a unified vector space where different content types can be meaningfully compared. This requires specialized embedding models that understand semantic relationships across modalities.</p>
<p><strong>Implementation Architecture:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="p">{</span>
<a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a><span class="w">  </span><span class="nt">&quot;mappings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a><span class="w">    </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a><span class="w">      </span><span class="nt">&quot;content_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="p">},</span>
<a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a><span class="w">      </span><span class="nt">&quot;content_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="p">},</span>
<a id="__codelineno-31-6" name="__codelineno-31-6" href="#__codelineno-31-6"></a><span class="w">      </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">},</span>
<a id="__codelineno-31-7" name="__codelineno-31-7" href="#__codelineno-31-7"></a><span class="w">      </span><span class="nt">&quot;description&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">},</span>
<a id="__codelineno-31-8" name="__codelineno-31-8" href="#__codelineno-31-8"></a>
<a id="__codelineno-31-9" name="__codelineno-31-9" href="#__codelineno-31-9"></a><span class="w">      </span><span class="nt">&quot;text_embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-10" name="__codelineno-31-10" href="#__codelineno-31-10"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-31-11" name="__codelineno-31-11" href="#__codelineno-31-11"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span>
<a id="__codelineno-31-12" name="__codelineno-31-12" href="#__codelineno-31-12"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-13" name="__codelineno-31-13" href="#__codelineno-31-13"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;hnsw&quot;</span><span class="p">,</span>
<a id="__codelineno-31-14" name="__codelineno-31-14" href="#__codelineno-31-14"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cosinesimil&quot;</span><span class="p">,</span>
<a id="__codelineno-31-15" name="__codelineno-31-15" href="#__codelineno-31-15"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;ef_construction&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;m&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">}</span>
<a id="__codelineno-31-16" name="__codelineno-31-16" href="#__codelineno-31-16"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-31-17" name="__codelineno-31-17" href="#__codelineno-31-17"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-31-18" name="__codelineno-31-18" href="#__codelineno-31-18"></a>
<a id="__codelineno-31-19" name="__codelineno-31-19" href="#__codelineno-31-19"></a><span class="w">      </span><span class="nt">&quot;image_embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-20" name="__codelineno-31-20" href="#__codelineno-31-20"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-31-21" name="__codelineno-31-21" href="#__codelineno-31-21"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span>
<a id="__codelineno-31-22" name="__codelineno-31-22" href="#__codelineno-31-22"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-23" name="__codelineno-31-23" href="#__codelineno-31-23"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;hnsw&quot;</span><span class="p">,</span>
<a id="__codelineno-31-24" name="__codelineno-31-24" href="#__codelineno-31-24"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cosinesimil&quot;</span><span class="p">,</span>
<a id="__codelineno-31-25" name="__codelineno-31-25" href="#__codelineno-31-25"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;ef_construction&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;m&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">}</span>
<a id="__codelineno-31-26" name="__codelineno-31-26" href="#__codelineno-31-26"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-31-27" name="__codelineno-31-27" href="#__codelineno-31-27"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-31-28" name="__codelineno-31-28" href="#__codelineno-31-28"></a>
<a id="__codelineno-31-29" name="__codelineno-31-29" href="#__codelineno-31-29"></a><span class="w">      </span><span class="nt">&quot;unified_embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-30" name="__codelineno-31-30" href="#__codelineno-31-30"></a><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;knn_vector&quot;</span><span class="p">,</span>
<a id="__codelineno-31-31" name="__codelineno-31-31" href="#__codelineno-31-31"></a><span class="w">        </span><span class="nt">&quot;dimension&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span>
<a id="__codelineno-31-32" name="__codelineno-31-32" href="#__codelineno-31-32"></a><span class="w">        </span><span class="nt">&quot;method&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-31-33" name="__codelineno-31-33" href="#__codelineno-31-33"></a><span class="w">          </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;hnsw&quot;</span><span class="p">,</span>
<a id="__codelineno-31-34" name="__codelineno-31-34" href="#__codelineno-31-34"></a><span class="w">          </span><span class="nt">&quot;space_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cosinesimil&quot;</span><span class="p">,</span>
<a id="__codelineno-31-35" name="__codelineno-31-35" href="#__codelineno-31-35"></a><span class="w">          </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;ef_construction&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;m&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">}</span>
<a id="__codelineno-31-36" name="__codelineno-31-36" href="#__codelineno-31-36"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-31-37" name="__codelineno-31-37" href="#__codelineno-31-37"></a><span class="w">      </span><span class="p">}</span>
<a id="__codelineno-31-38" name="__codelineno-31-38" href="#__codelineno-31-38"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-31-39" name="__codelineno-31-39" href="#__codelineno-31-39"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-31-40" name="__codelineno-31-40" href="#__codelineno-31-40"></a><span class="p">}</span>
</code></pre></div>
<p><strong>Cross-Modal Query Examples:</strong></p>
<p><em>Text-to-Image Search:</em>
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="p">{</span>
<a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a><span class="w">  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a><span class="w">    </span><span class="nt">&quot;bool&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a><span class="w">      </span><span class="nt">&quot;must&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-32-5" name="__codelineno-32-5" href="#__codelineno-32-5"></a><span class="w">        </span><span class="p">{</span><span class="nt">&quot;term&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;content_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;image&quot;</span><span class="p">}},</span>
<a id="__codelineno-32-6" name="__codelineno-32-6" href="#__codelineno-32-6"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-32-7" name="__codelineno-32-7" href="#__codelineno-32-7"></a><span class="w">          </span><span class="nt">&quot;knn&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-32-8" name="__codelineno-32-8" href="#__codelineno-32-8"></a><span class="w">            </span><span class="nt">&quot;unified_embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-32-9" name="__codelineno-32-9" href="#__codelineno-32-9"></a><span class="w">              </span><span class="nt">&quot;vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.2</span><span class="p">,</span><span class="w"> </span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="err">...</span><span class="p">],</span>
<a id="__codelineno-32-10" name="__codelineno-32-10" href="#__codelineno-32-10"></a><span class="w">              </span><span class="nt">&quot;k&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span>
<a id="__codelineno-32-11" name="__codelineno-32-11" href="#__codelineno-32-11"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-32-12" name="__codelineno-32-12" href="#__codelineno-32-12"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-32-13" name="__codelineno-32-13" href="#__codelineno-32-13"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-32-14" name="__codelineno-32-14" href="#__codelineno-32-14"></a><span class="w">      </span><span class="p">]</span>
<a id="__codelineno-32-15" name="__codelineno-32-15" href="#__codelineno-32-15"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-32-16" name="__codelineno-32-16" href="#__codelineno-32-16"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-32-17" name="__codelineno-32-17" href="#__codelineno-32-17"></a><span class="p">}</span>
</code></pre></div></p>
<p><em>Image-to-Text Search:</em>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="p">{</span>
<a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a><span class="w">  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a><span class="w">    </span><span class="nt">&quot;bool&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-33-4" name="__codelineno-33-4" href="#__codelineno-33-4"></a><span class="w">      </span><span class="nt">&quot;must&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-33-5" name="__codelineno-33-5" href="#__codelineno-33-5"></a><span class="w">        </span><span class="p">{</span><span class="nt">&quot;term&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;content_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">}},</span>
<a id="__codelineno-33-6" name="__codelineno-33-6" href="#__codelineno-33-6"></a><span class="w">        </span><span class="p">{</span>
<a id="__codelineno-33-7" name="__codelineno-33-7" href="#__codelineno-33-7"></a><span class="w">          </span><span class="nt">&quot;knn&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-33-8" name="__codelineno-33-8" href="#__codelineno-33-8"></a><span class="w">            </span><span class="nt">&quot;unified_embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-33-9" name="__codelineno-33-9" href="#__codelineno-33-9"></a><span class="w">              </span><span class="nt">&quot;vector&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.4</span><span class="p">,</span><span class="w"> </span><span class="err">...</span><span class="p">],</span>
<a id="__codelineno-33-10" name="__codelineno-33-10" href="#__codelineno-33-10"></a><span class="w">              </span><span class="nt">&quot;k&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span>
<a id="__codelineno-33-11" name="__codelineno-33-11" href="#__codelineno-33-11"></a><span class="w">            </span><span class="p">}</span>
<a id="__codelineno-33-12" name="__codelineno-33-12" href="#__codelineno-33-12"></a><span class="w">          </span><span class="p">}</span>
<a id="__codelineno-33-13" name="__codelineno-33-13" href="#__codelineno-33-13"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-33-14" name="__codelineno-33-14" href="#__codelineno-33-14"></a><span class="w">      </span><span class="p">]</span>
<a id="__codelineno-33-15" name="__codelineno-33-15" href="#__codelineno-33-15"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-33-16" name="__codelineno-33-16" href="#__codelineno-33-16"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-33-17" name="__codelineno-33-17" href="#__codelineno-33-17"></a><span class="p">}</span>
</code></pre></div></p>
<p><strong>Multi-Modal Embedding Models:</strong></p>
<ul>
<li><strong>CLIP (OpenAI):</strong> Text-image understanding with 512-dimensional embeddings</li>
<li><strong>ALIGN (Google):</strong> Large-scale text-image alignment with 640-dimensional vectors</li>
<li><strong>AudioCLIP:</strong> Extension to audio-text-image modalities</li>
<li><strong>VideoCLIP:</strong> Video-text understanding for temporal content</li>
</ul>
<p><strong>Practical Implementation Considerations:</strong></p>
<ul>
<li><strong>Dimension Alignment:</strong> Ensure all modalities use the same vector dimensions</li>
<li><strong>Normalization:</strong> Apply consistent normalization across different embedding models</li>
<li><strong>Quality Control:</strong> Validate cross-modal similarity using human evaluation</li>
<li><strong>Performance Optimization:</strong> Use separate indexes per modality for complex queries </li>
</ul>
<p><em>Implementation included in:</em> <a href="../search_examples/#cross-modal-search-functions">Cross-Modal Search Functions</a></p>
<p>This comprehensive guide provides the foundation for building production-ready vector search systems with OpenSearch. The progression from traditional text search through advanced hybrid approaches, combined with deep algorithmic understanding and practical implementation patterns, enables you to create sophisticated search experiences that understand meaning rather than just matching keywords.</p>
<p>The key to successful vector search implementation lies in understanding your specific use case requirements, choosing appropriate algorithms and parameters, and continuously monitoring and optimizing performance based on real-world usage patterns.</p>
<hr />
<h2 id="-performance-metrics-disclaimer">⚠️ Performance Metrics Disclaimer<a class="headerlink" href="#-performance-metrics-disclaimer" title="Permanent link">&para;</a></h2>
<p><strong>Important Notice about Performance Data:</strong></p>
<p>All performance metrics, benchmarks, latency figures, memory usage statistics, and cost examples presented in this document are <strong>illustrative examples</strong> designed to help with understanding and planning. These numbers are based on theoretical models, synthetic tests, or specific hardware configurations and should not be considered as guaranteed performance metrics for your specific use case.</p>
<p><strong>Actual performance will vary significantly based on:</strong></p>
<ul>
<li>Hardware specifications and configurations</li>
<li>Data characteristics (vector dimensions, dataset size, distribution)</li>
<li>Query patterns and concurrency levels</li>
<li>Network latency and infrastructure setup</li>
<li>OpenSearch version and configuration settings</li>
<li>Operating system and environment factors</li>
</ul>
<p><strong>Before making production decisions:</strong></p>
<ul>
<li>Conduct benchmarks with your actual data and infrastructure</li>
<li>Test with realistic query patterns and load</li>
<li>Consult official OpenSearch and AWS documentation for current capabilities</li>
<li>Consider engaging with AWS support for production sizing guidance</li>
</ul>
<p>For current official benchmarks and performance guidance, refer to:
- <a href="https://opensearch.org/docs/latest/tuning/">OpenSearch Performance Guidelines</a>
- <a href="https://docs.aws.amazon.com/opensearch-service/latest/developerguide/bp.html">AWS OpenSearch Service Best Practices</a></p>
<hr />












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "navigation.top", "navigation.instant", "content.code.copy", "content.tabs.link", "toc.follow"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
    
  </body>
</html>